"""
FrequencyChannelAttentionV3 (Global-Local åŒæµèåˆ) æµ‹è¯•æ–‡ä»¶

æµ‹è¯•å†…å®¹:
1. åŸºç¡€å‰å‘ä¼ æ’­æµ‹è¯•
2. V1 vs V2 vs V3 å¯¹æ¯”æµ‹è¯•
3. å¯å­¦ä¹  alpha å‚æ•°æµ‹è¯•
4. æ¢¯åº¦æµæµ‹è¯•
5. Global/Local åˆ†æ”¯ç‹¬ç«‹æ€§æµ‹è¯•
6. å‚æ•°é‡å¯¹æ¯”æµ‹è¯•
"""

import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

import torch
import torch.nn as nn
import numpy as np


def test_v3_basic_forward():
    """æµ‹è¯• V3 åŸºç¡€å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 1: V3 åŸºç¡€å‰å‘ä¼ æ’­")
    print("=" * 70)
    
    from layers.Embed import FrequencyChannelAttentionV3
    
    # å‚æ•°
    batch_size = 4
    num_patches = 32
    d_model = 64
    num_bands = 3
    
    # åˆ›å»ºæ¨¡å—
    v3 = FrequencyChannelAttentionV3(
        num_bands=num_bands,
        d_model=d_model,
        reduction=4,
        kernel_size=3
    )
    
    # åˆ›å»ºè¾“å…¥
    band_embeddings = [
        torch.randn(batch_size, num_patches, d_model)
        for _ in range(num_bands)
    ]
    
    # å‰å‘ä¼ æ’­
    output, attention_weights, fusion_info = v3(band_embeddings)
    
    # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
    assert output.shape == (batch_size, num_patches, d_model), \
        f"è¾“å‡ºå½¢çŠ¶é”™è¯¯: æœŸæœ› {(batch_size, num_patches, d_model)}, å®é™… {output.shape}"
    assert attention_weights.shape == (batch_size, num_patches, num_bands), \
        f"æƒé‡å½¢çŠ¶é”™è¯¯: æœŸæœ› {(batch_size, num_patches, num_bands)}, å®é™… {attention_weights.shape}"
    
    # æ£€æŸ¥æƒé‡å’Œä¸º 1
    weight_sum = attention_weights.sum(dim=-1)
    assert torch.allclose(weight_sum, torch.ones_like(weight_sum), atol=1e-5), \
        "æƒé‡å’Œä¸ä¸º 1"
    
    # æ£€æŸ¥ fusion_info
    assert 'alpha' in fusion_info, "fusion_info ç¼ºå°‘ alpha"
    assert 'global_weights' in fusion_info, "fusion_info ç¼ºå°‘ global_weights"
    assert 'local_weights' in fusion_info, "fusion_info ç¼ºå°‘ local_weights"
    
    print(f"âœ… è¾“å‡ºå½¢çŠ¶æ­£ç¡®: {output.shape}")
    print(f"âœ… æƒé‡å½¢çŠ¶æ­£ç¡®: {attention_weights.shape}")
    print(f"âœ… æƒé‡å’Œä¸º 1")
    print(f"âœ… Alpha å€¼: {fusion_info['alpha']:.4f}")
    print("âœ… æµ‹è¯•é€šè¿‡!")
    
    return True


def test_v1_v2_v3_comparison():
    """å¯¹æ¯” V1, V2, V3 çš„è¾“å‡º"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 2: V1 vs V2 vs V3 å¯¹æ¯”")
    print("=" * 70)
    
    from layers.Embed import (
        FrequencyChannelAttention,
        FrequencyChannelAttentionV2,
        FrequencyChannelAttentionV3
    )
    
    # å‚æ•°
    batch_size = 4
    num_patches = 32
    d_model = 64
    num_bands = 3
    
    # åˆ›å»ºä¸‰ä¸ªç‰ˆæœ¬
    v1 = FrequencyChannelAttention(num_bands=num_bands, d_model=d_model, reduction=4)
    v2 = FrequencyChannelAttentionV2(num_bands=num_bands, d_model=d_model, reduction=4, kernel_size=3)
    v3 = FrequencyChannelAttentionV3(num_bands=num_bands, d_model=d_model, reduction=4, kernel_size=3)
    
    # ç”¨éšæœºå€¼åˆå§‹åŒ– V2/V3 çš„ MLP æœ€åä¸€å±‚ï¼Œä»¥ä¾¿æµ‹è¯• Patch-wise ç‰¹æ€§
    # (é»˜è®¤åˆå§‹åŒ–ä¸º 0 æ˜¯ä¸ºäº†è®©åˆå§‹æƒé‡å‡åŒ€ï¼Œä½†è¿™é‡Œéœ€è¦éªŒè¯æ¶æ„èƒ½åŠ›)
    with torch.no_grad():
        nn.init.normal_(v2.excitation[-1].weight, std=0.1)
        nn.init.normal_(v2.excitation[-1].bias, std=0.1)
        nn.init.normal_(v3.local_excitation[-1].weight, std=0.1)
        nn.init.normal_(v3.local_excitation[-1].bias, std=0.1)
    
    # ç›¸åŒè¾“å…¥
    torch.manual_seed(42)
    band_embeddings = [
        torch.randn(batch_size, num_patches, d_model)
        for _ in range(num_bands)
    ]
    
    # å‰å‘ä¼ æ’­
    out_v1, weights_v1 = v1(band_embeddings)
    out_v2, weights_v2 = v2(band_embeddings)
    out_v3, weights_v3, fusion_info = v3(band_embeddings)
    
    # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
    assert out_v1.shape == out_v2.shape == out_v3.shape, "è¾“å‡ºå½¢çŠ¶ä¸ä¸€è‡´"
    
    # V1 æƒé‡æ˜¯ Instance-wise (æ‰€æœ‰ Patch å…±äº«)
    # V2/V3 æƒé‡æ˜¯ Patch-wise (æ¯ä¸ª Patch ç‹¬ç«‹)
    v1_weight_std = weights_v1.std(dim=1).mean().item()  # æ²¿ Patch ç»´åº¦çš„æ ‡å‡†å·® (åº”è¯¥ä¸º 0)
    v2_weight_std = weights_v2.std(dim=1).mean().item()  # åº”è¯¥ > 0
    v3_weight_std = weights_v3.std(dim=1).mean().item()  # åº”è¯¥ > 0
    
    print(f"V1 æƒé‡ Patch é—´æ ‡å‡†å·®: {v1_weight_std:.6f} (åº”æ¥è¿‘ 0)")
    print(f"V2 æƒé‡ Patch é—´æ ‡å‡†å·®: {v2_weight_std:.6f} (åº” > 0)")
    print(f"V3 æƒé‡ Patch é—´æ ‡å‡†å·®: {v3_weight_std:.6f} (åº” > 0)")
    
    assert v1_weight_std < 1e-5, "V1 æƒé‡åº”è¯¥æ˜¯ Instance-wise çš„"
    assert v2_weight_std > 1e-5, "V2 æƒé‡åº”è¯¥æ˜¯ Patch-wise çš„"
    assert v3_weight_std > 1e-5, "V3 æƒé‡åº”è¯¥æ˜¯ Patch-wise çš„"
    
    print(f"âœ… V1 æ˜¯ Instance-wise (æƒé‡è·¨ Patch ä¸€è‡´)")
    print(f"âœ… V2 æ˜¯ Patch-wise (æƒé‡è·¨ Patch å˜åŒ–)")
    print(f"âœ… V3 æ˜¯ Patch-wise (æƒé‡è·¨ Patch å˜åŒ–)")
    print("âœ… æµ‹è¯•é€šè¿‡!")
    
    return True


def test_learnable_alpha():
    """æµ‹è¯•å¯å­¦ä¹ çš„ alpha å‚æ•°"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 3: å¯å­¦ä¹  Alpha å‚æ•°")
    print("=" * 70)
    
    from layers.Embed import FrequencyChannelAttentionV3
    
    # å‚æ•°
    batch_size = 4
    num_patches = 32
    d_model = 64
    num_bands = 3
    
    # åˆ›å»ºæ¨¡å—
    v3 = FrequencyChannelAttentionV3(
        num_bands=num_bands,
        d_model=d_model,
        reduction=4,
        kernel_size=3
    )
    
    # æ£€æŸ¥ alpha æ˜¯å¦æ˜¯å¯å­¦ä¹ å‚æ•°
    alpha_found = False
    for name, param in v3.named_parameters():
        if 'alpha' in name:
            alpha_found = True
            print(f"âœ… æ‰¾åˆ° alpha å‚æ•°: {name}, å€¼={param.item():.4f}, requires_grad={param.requires_grad}")
            assert param.requires_grad, "Alpha åº”è¯¥æ˜¯å¯å­¦ä¹ çš„"
    
    assert alpha_found, "æœªæ‰¾åˆ° alpha å‚æ•°"
    
    # æ¨¡æ‹Ÿè®­ç»ƒ: æ£€æŸ¥ alpha æ˜¯å¦ä¼šæ›´æ–°
    optimizer = torch.optim.SGD(v3.parameters(), lr=0.1)
    
    band_embeddings = [
        torch.randn(batch_size, num_patches, d_model)
        for _ in range(num_bands)
    ]
    target = torch.randn(batch_size, num_patches, d_model)
    
    initial_alpha = v3.alpha.item()
    
    # å¤šæ¬¡æ¢¯åº¦æ›´æ–°
    for _ in range(10):
        optimizer.zero_grad()
        output, _, _ = v3(band_embeddings)
        loss = ((output - target) ** 2).mean()
        loss.backward()
        optimizer.step()
    
    updated_alpha = v3.alpha.item()
    
    print(f"åˆå§‹ alpha: {initial_alpha:.4f}")
    print(f"æ›´æ–°å alpha: {updated_alpha:.4f}")
    print(f"å˜åŒ–é‡: {abs(updated_alpha - initial_alpha):.6f}")
    
    assert abs(updated_alpha - initial_alpha) > 1e-6, "Alpha åº”è¯¥åœ¨è®­ç»ƒä¸­æ›´æ–°"
    print("âœ… Alpha åœ¨è®­ç»ƒä¸­æˆåŠŸæ›´æ–°!")
    print("âœ… æµ‹è¯•é€šè¿‡!")
    
    return True


def test_gradient_flow():
    """æµ‹è¯•æ¢¯åº¦æµé€š"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 4: æ¢¯åº¦æµé€š")
    print("=" * 70)
    
    from layers.Embed import FrequencyChannelAttentionV3
    
    # å‚æ•°
    batch_size = 4
    num_patches = 32
    d_model = 64
    num_bands = 3
    
    # åˆ›å»ºæ¨¡å—
    v3 = FrequencyChannelAttentionV3(
        num_bands=num_bands,
        d_model=d_model,
        reduction=4,
        kernel_size=3
    )
    
    # åˆ›å»ºéœ€è¦æ¢¯åº¦çš„è¾“å…¥
    band_embeddings = [
        torch.randn(batch_size, num_patches, d_model, requires_grad=True)
        for _ in range(num_bands)
    ]
    
    # å‰å‘ä¼ æ’­
    output, _, _ = v3(band_embeddings)
    
    # åå‘ä¼ æ’­
    loss = output.sum()
    loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    for i, emb in enumerate(band_embeddings):
        assert emb.grad is not None, f"é¢‘æ®µ {i} æ²¡æœ‰æ¢¯åº¦"
        assert not torch.isnan(emb.grad).any(), f"é¢‘æ®µ {i} æ¢¯åº¦åŒ…å« NaN"
        grad_norm = emb.grad.norm().item()
        print(f"é¢‘æ®µ {i} æ¢¯åº¦èŒƒæ•°: {grad_norm:.6f}")
    
    # æ£€æŸ¥æ¨¡å‹å‚æ•°æ¢¯åº¦
    for name, param in v3.named_parameters():
        if param.grad is not None:
            grad_norm = param.grad.norm().item()
            print(f"å‚æ•° {name}: æ¢¯åº¦èŒƒæ•°={grad_norm:.6f}")
            assert not torch.isnan(param.grad).any(), f"å‚æ•° {name} æ¢¯åº¦åŒ…å« NaN"
    
    print("âœ… æ‰€æœ‰æ¢¯åº¦æ­£å¸¸æµé€š!")
    print("âœ… æµ‹è¯•é€šè¿‡!")
    
    return True


def test_global_local_decomposition():
    """æµ‹è¯• Global å’Œ Local åˆ†æ”¯çš„åˆ†è§£æ•ˆæœ"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 5: Global/Local åˆ†æ”¯åˆ†è§£æ•ˆæœ")
    print("=" * 70)
    
    from layers.Embed import FrequencyChannelAttentionV3
    
    # å‚æ•°
    batch_size = 4
    num_patches = 32
    d_model = 64
    num_bands = 3
    
    # åˆ›å»ºæ¨¡å—
    v3 = FrequencyChannelAttentionV3(
        num_bands=num_bands,
        d_model=d_model,
        reduction=4,
        kernel_size=3
    )
    
    # ç”¨éšæœºå€¼åˆå§‹åŒ– Local MLP æœ€åä¸€å±‚ï¼Œä»¥ä¾¿æµ‹è¯• Patch-wise ç‰¹æ€§
    # (é»˜è®¤åˆå§‹åŒ–ä¸º 0 æ˜¯ä¸ºäº†è®©åˆå§‹æƒé‡å‡åŒ€ï¼Œä½†è¿™é‡Œéœ€è¦éªŒè¯æ¶æ„èƒ½åŠ›)
    with torch.no_grad():
        nn.init.normal_(v3.local_excitation[-1].weight, std=0.1)
        nn.init.normal_(v3.local_excitation[-1].bias, std=0.1)
    
    # åˆ›å»ºè¾“å…¥
    torch.manual_seed(42)
    band_embeddings = [
        torch.randn(batch_size, num_patches, d_model)
        for _ in range(num_bands)
    ]
    
    # å‰å‘ä¼ æ’­
    output, attention_weights, fusion_info = v3(band_embeddings)
    
    # æ£€æŸ¥ Global æƒé‡ (åº”è¯¥åœ¨ Patch ç»´åº¦ä¸Šä¸€è‡´)
    global_weights = fusion_info['global_weights']
    global_std = global_weights.std(dim=1).mean().item()
    print(f"Global æƒé‡ Patch é—´æ ‡å‡†å·®: {global_std:.6f} (åº”æ¥è¿‘ 0)")
    assert global_std < 1e-5, "Global æƒé‡åº”è¯¥è·¨ Patch ä¸€è‡´"
    
    # æ£€æŸ¥ Local æƒé‡ (åº”è¯¥åœ¨ Patch ç»´åº¦ä¸Šå˜åŒ–)
    local_weights = fusion_info['local_weights']
    local_std = local_weights.std(dim=1).mean().item()
    print(f"Local æƒé‡ Patch é—´æ ‡å‡†å·®: {local_std:.6f} (åº” > 0)")
    assert local_std > 1e-5, "Local æƒé‡åº”è¯¥è·¨ Patch å˜åŒ–"
    
    # æ£€æŸ¥èåˆæƒé‡ (ä»‹äº Global å’Œ Local ä¹‹é—´)
    fused_std = attention_weights.std(dim=1).mean().item()
    print(f"èåˆæƒé‡ Patch é—´æ ‡å‡†å·®: {fused_std:.6f}")
    
    print(f"âœ… Global åˆ†æ”¯: Instance-wise (è·¨ Patch ä¸€è‡´)")
    print(f"âœ… Local åˆ†æ”¯: Patch-wise (è·¨ Patch å˜åŒ–)")
    print(f"âœ… èåˆæƒé‡: ç»“åˆäº†ä¸¤è€…ç‰¹æ€§")
    print("âœ… æµ‹è¯•é€šè¿‡!")
    
    return True


def test_parameter_count():
    """å¯¹æ¯” V1, V2, V3 çš„å‚æ•°é‡"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 6: å‚æ•°é‡å¯¹æ¯”")
    print("=" * 70)
    
    from layers.Embed import (
        FrequencyChannelAttention,
        FrequencyChannelAttentionV2,
        FrequencyChannelAttentionV3
    )
    
    # å‚æ•°
    d_model = 64
    num_bands = 3
    
    v1 = FrequencyChannelAttention(num_bands=num_bands, d_model=d_model, reduction=4)
    v2 = FrequencyChannelAttentionV2(num_bands=num_bands, d_model=d_model, reduction=4, kernel_size=3)
    v3 = FrequencyChannelAttentionV3(num_bands=num_bands, d_model=d_model, reduction=4, kernel_size=3)
    
    def count_params(model):
        return sum(p.numel() for p in model.parameters())
    
    v1_params = count_params(v1)
    v2_params = count_params(v2)
    v3_params = count_params(v3)
    
    print(f"V1 (GAP) å‚æ•°é‡: {v1_params:,}")
    print(f"V2 (1D Conv) å‚æ•°é‡: {v2_params:,}")
    print(f"V3 (Global-Local) å‚æ•°é‡: {v3_params:,}")
    print(f"V3/V1 æ¯”ä¾‹: {v3_params/v1_params:.2f}x")
    print(f"V3/V2 æ¯”ä¾‹: {v3_params/v2_params:.2f}x")
    
    # V3 åº”è¯¥æ¯” V2 å¤šä¸€äº›å‚æ•° (Global MLP)
    assert v3_params > v2_params, "V3 å‚æ•°é‡åº”å¤§äº V2"
    
    print("âœ… å‚æ•°é‡ç¬¦åˆé¢„æœŸ!")
    print("âœ… æµ‹è¯•é€šè¿‡!")
    
    return True


def test_alpha_range():
    """æµ‹è¯• alpha å€¼çš„èŒƒå›´é™åˆ¶"""
    print("\n" + "=" * 70)
    print("æµ‹è¯• 7: Alpha å€¼èŒƒå›´é™åˆ¶")
    print("=" * 70)
    
    from layers.Embed import FrequencyChannelAttentionV3
    
    # å‚æ•°
    batch_size = 4
    num_patches = 32
    d_model = 64
    num_bands = 3
    
    # åˆ›å»ºæ¨¡å—
    v3 = FrequencyChannelAttentionV3(
        num_bands=num_bands,
        d_model=d_model,
        reduction=4,
        kernel_size=3
    )
    
    # æµ‹è¯•æç«¯ alpha å€¼
    test_values = [-10.0, -1.0, 0.0, 0.5, 1.0, 10.0]
    
    for val in test_values:
        v3.alpha.data = torch.tensor(val)
        
        band_embeddings = [
            torch.randn(batch_size, num_patches, d_model)
            for _ in range(num_bands)
        ]
        
        output, _, fusion_info = v3(band_embeddings)
        alpha = fusion_info['alpha']
        
        print(f"è®¾ç½® alpha={val:.1f}, å®é™…ä½¿ç”¨ alpha={alpha:.4f}")
        
        # alpha ç»è¿‡ sigmoid ååº”è¯¥åœ¨ [0, 1] èŒƒå›´å†…
        assert 0 <= alpha <= 1, f"Alpha åº”è¯¥åœ¨ [0, 1] èŒƒå›´å†…, å®é™…å€¼: {alpha}"
    
    print("âœ… Alpha å€¼å§‹ç»ˆåœ¨ [0, 1] èŒƒå›´å†…!")
    print("âœ… æµ‹è¯•é€šè¿‡!")
    
    return True


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\n" + "=" * 70)
    print("FrequencyChannelAttentionV3 (Global-Local åŒæµèåˆ) å®Œæ•´æµ‹è¯•")
    print("=" * 70)
    
    tests = [
        ("åŸºç¡€å‰å‘ä¼ æ’­", test_v3_basic_forward),
        ("V1 vs V2 vs V3 å¯¹æ¯”", test_v1_v2_v3_comparison),
        ("å¯å­¦ä¹  Alpha å‚æ•°", test_learnable_alpha),
        ("æ¢¯åº¦æµé€š", test_gradient_flow),
        ("Global/Local åˆ†æ”¯åˆ†è§£", test_global_local_decomposition),
        ("å‚æ•°é‡å¯¹æ¯”", test_parameter_count),
        ("Alpha å€¼èŒƒå›´é™åˆ¶", test_alpha_range),
    ]
    
    results = []
    for name, test_func in tests:
        try:
            success = test_func()
            results.append((name, success))
        except Exception as e:
            print(f"âŒ æµ‹è¯• '{name}' å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            results.append((name, False))
    
    # æ‰“å°æ€»ç»“
    print("\n" + "=" * 70)
    print("æµ‹è¯•æ€»ç»“")
    print("=" * 70)
    
    passed = sum(1 for _, success in results if success)
    total = len(results)
    
    for name, success in results:
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"  {status}: {name}")
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡! FrequencyChannelAttentionV3 å®ç°æ­£ç¡®!")
    else:
        print(f"\nâš ï¸ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥å®ç°!")
    
    return passed == total


if __name__ == "__main__":
    run_all_tests()

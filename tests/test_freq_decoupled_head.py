"""
é¢‘ç‡è§£è€¦è¾“å‡ºå¤´ (Frequency Decoupled Head) å…¨é¢æµ‹è¯•

æµ‹è¯•å†…å®¹:
1. TriBandDecoupledHead åŸºæœ¬åŠŸèƒ½æµ‹è¯•
2. SoftThreshold æ¨¡å—æµ‹è¯•
3. DeepSupervisionLoss æ¨¡å—æµ‹è¯•
4. ä¸ TimeLLM æ¨¡å‹çš„é›†æˆæµ‹è¯•
5. æ¢¯åº¦ä¼ æ’­æµ‹è¯•
6. ä¸åŒé…ç½®ç»„åˆæµ‹è¯•
7. è¾¹ç•Œæ¡ä»¶æµ‹è¯•
8. æ€§èƒ½åŸºå‡†æµ‹è¯•

Author: CAST Project
Date: 2024
"""

import sys
import os
import unittest
import torch
import torch.nn as nn
import torch.nn.functional as F
import numpy as np
import time
from typing import Dict, Tuple, Optional

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, project_root)

from layers.FrequencyDecoupledHead import (
    TriBandDecoupledHead,
    DeepSupervisionLoss,
    SoftThreshold
)


class TestSoftThreshold(unittest.TestCase):
    """SoftThreshold æ¨¡å—æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        self.num_features = 64
        self.batch_size = 4
    
    def test_basic_forward(self):
        """æµ‹è¯•åŸºæœ¬å‰å‘ä¼ æ’­"""
        st = SoftThreshold(self.num_features, init_tau=0.1).to(self.device)
        x = torch.randn(self.batch_size, self.num_features, device=self.device)
        y = st(x)
        
        self.assertEqual(y.shape, x.shape)
        print("âœ… SoftThreshold åŸºæœ¬å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")
    
    def test_thresholding_behavior(self):
        """æµ‹è¯•é˜ˆå€¼è¡Œä¸ºï¼šå°äºé˜ˆå€¼çš„å€¼åº”è¢«ç½®é›¶"""
        st = SoftThreshold(self.num_features, init_tau=0.5).to(self.device)
        
        # åˆ›å»ºåŒ…å«å°å€¼å’Œå¤§å€¼çš„è¾“å…¥
        x = torch.tensor([[0.1, 0.3, 0.6, 0.8, -0.2, -0.7]], device=self.device)
        st_single = SoftThreshold(6, init_tau=0.5).to(self.device)
        y = st_single(x)
        
        # æ£€æŸ¥å°äºé˜ˆå€¼çš„å€¼æ˜¯å¦è¢«ç½®é›¶
        tau = 0.5
        expected_zero_mask = x.abs() < tau
        actual_zero = (y == 0)
        
        self.assertTrue(torch.all(actual_zero[expected_zero_mask]))
        print("âœ… SoftThreshold é˜ˆå€¼è¡Œä¸ºæµ‹è¯•é€šè¿‡")
    
    def test_gradient_flow(self):
        """æµ‹è¯•æ¢¯åº¦æµ"""
        st = SoftThreshold(self.num_features, init_tau=0.1).to(self.device)
        x = torch.randn(self.batch_size, self.num_features, device=self.device, requires_grad=True)
        
        y = st(x)
        loss = y.sum()
        loss.backward()
        
        # æ£€æŸ¥è¾“å…¥å’Œå‚æ•°éƒ½æœ‰æ¢¯åº¦
        self.assertIsNotNone(x.grad)
        self.assertIsNotNone(st.tau.grad)
        self.assertTrue(x.grad.abs().sum() > 0)
        print("âœ… SoftThreshold æ¢¯åº¦æµæµ‹è¯•é€šè¿‡")
    
    def test_learnable_tau(self):
        """æµ‹è¯•å¯å­¦ä¹ é˜ˆå€¼"""
        st = SoftThreshold(self.num_features, init_tau=0.1).to(self.device)
        
        # åˆå§‹é˜ˆå€¼
        initial_tau = st.tau.clone()
        
        # æ¨¡æ‹Ÿè®­ç»ƒ
        optimizer = torch.optim.SGD([st.tau], lr=0.1)
        for _ in range(10):
            x = torch.randn(self.batch_size, self.num_features, device=self.device)
            y = st(x)
            loss = y.abs().sum()
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
        
        # æ£€æŸ¥é˜ˆå€¼æ˜¯å¦æ”¹å˜
        self.assertFalse(torch.allclose(st.tau, initial_tau))
        print("âœ… SoftThreshold å¯å­¦ä¹ é˜ˆå€¼æµ‹è¯•é€šè¿‡")


class TestTriBandDecoupledHead(unittest.TestCase):
    """TriBandDecoupledHead æ¨¡å—æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        self.batch_size = 4
        self.n_vars = 7
        self.d_ff = 32
        self.patch_nums = 10
        self.nf = self.d_ff * self.patch_nums
        self.pred_len = 96
    
    def _create_head(self, **kwargs) -> TriBandDecoupledHead:
        """åˆ›å»ºæµ‹è¯•ç”¨çš„ Head"""
        default_kwargs = {
            'n_vars': self.n_vars,
            'nf': self.nf,
            'target_window': self.pred_len,
            'head_dropout': 0.1,
            'mid_dropout': 0.2,
            'high_dropout': 0.5,
            'use_soft_threshold': True,
            'soft_threshold_init': 0.1,
            'use_conv': False,
        }
        default_kwargs.update(kwargs)
        return TriBandDecoupledHead(**default_kwargs).to(self.device)
    
    def _create_input(self) -> torch.Tensor:
        """åˆ›å»ºæµ‹è¯•è¾“å…¥"""
        return torch.randn(
            self.batch_size, self.n_vars, self.d_ff, self.patch_nums,
            device=self.device
        )
    
    def test_basic_forward_4d_input(self):
        """æµ‹è¯• 4D è¾“å…¥çš„å‰å‘ä¼ æ’­"""
        head = self._create_head()
        x = self._create_input()
        
        output = head(x, return_components=False)
        
        expected_shape = (self.batch_size, self.pred_len, self.n_vars)
        self.assertEqual(output.shape, expected_shape)
        print("âœ… TriBandDecoupledHead 4D è¾“å…¥å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")
    
    def test_basic_forward_3d_input(self):
        """æµ‹è¯• 3D è¾“å…¥çš„å‰å‘ä¼ æ’­"""
        head = self._create_head()
        x = torch.randn(self.batch_size, self.n_vars, self.nf, device=self.device)
        
        output = head(x, return_components=False)
        
        expected_shape = (self.batch_size, self.pred_len, self.n_vars)
        self.assertEqual(output.shape, expected_shape)
        print("âœ… TriBandDecoupledHead 3D è¾“å…¥å‰å‘ä¼ æ’­æµ‹è¯•é€šè¿‡")
    
    def test_return_components(self):
        """æµ‹è¯•è¿”å›é¢‘ç‡åˆ†é‡"""
        head = self._create_head()
        x = self._create_input()
        
        output, components = head(x, return_components=True)
        
        # æ£€æŸ¥è¾“å‡ºå½¢çŠ¶
        expected_shape = (self.batch_size, self.pred_len, self.n_vars)
        self.assertEqual(output.shape, expected_shape)
        
        # æ£€æŸ¥åˆ†é‡
        self.assertIn('pred_trend', components)
        self.assertIn('pred_mid', components)
        self.assertIn('pred_detail', components)
        
        for key, comp in components.items():
            self.assertEqual(comp.shape, expected_shape, f"{key} å½¢çŠ¶é”™è¯¯")
        
        print("âœ… TriBandDecoupledHead è¿”å›é¢‘ç‡åˆ†é‡æµ‹è¯•é€šè¿‡")
    
    def test_component_sum_equals_output_eval_mode(self):
        """æµ‹è¯• eval æ¨¡å¼ä¸‹åˆ†é‡ç›¸åŠ ç­‰äºè¾“å‡º"""
        head = self._create_head()
        head.eval()
        x = self._create_input()
        
        with torch.no_grad():
            output, components = head(x, return_components=True)
            reconstructed = (
                components['pred_trend'] + 
                components['pred_mid'] + 
                components['pred_detail']
            )
        
        diff = (output - reconstructed).abs().max().item()
        self.assertLess(diff, 1e-5, f"åˆ†é‡é‡æ„è¯¯å·®è¿‡å¤§: {diff}")
        print("âœ… TriBandDecoupledHead åˆ†é‡é‡æ„ä¸€è‡´æ€§æµ‹è¯•é€šè¿‡")
    
    def test_conv1d_mode(self):
        """æµ‹è¯• Conv1d æ¨¡å¼"""
        head = self._create_head(use_conv=True)
        x = self._create_input()
        
        output = head(x)
        
        expected_shape = (self.batch_size, self.pred_len, self.n_vars)
        self.assertEqual(output.shape, expected_shape)
        print("âœ… TriBandDecoupledHead Conv1d æ¨¡å¼æµ‹è¯•é€šè¿‡")
    
    def test_no_soft_threshold(self):
        """æµ‹è¯•å…³é—­ SoftThreshold"""
        head = self._create_head(use_soft_threshold=False)
        x = self._create_input()
        
        output = head(x)
        
        expected_shape = (self.batch_size, self.pred_len, self.n_vars)
        self.assertEqual(output.shape, expected_shape)
        print("âœ… TriBandDecoupledHead å…³é—­ SoftThreshold æµ‹è¯•é€šè¿‡")
    
    def test_gradient_flow(self):
        """æµ‹è¯•æ¢¯åº¦ä¼ æ’­"""
        head = self._create_head()
        head.train()
        x = self._create_input()
        x.requires_grad = True
        
        output, components = head(x, return_components=True)
        loss = output.sum() + sum(c.sum() for c in components.values())
        loss.backward()
        
        # æ£€æŸ¥è¾“å…¥æ¢¯åº¦
        self.assertIsNotNone(x.grad)
        self.assertTrue(x.grad.abs().sum() > 0)
        
        # æ£€æŸ¥æ‰€æœ‰å‚æ•°éƒ½æœ‰æ¢¯åº¦
        for name, param in head.named_parameters():
            if param.requires_grad:
                self.assertIsNotNone(param.grad, f"{name} æ²¡æœ‰æ¢¯åº¦")
        
        print("âœ… TriBandDecoupledHead æ¢¯åº¦ä¼ æ’­æµ‹è¯•é€šè¿‡")
    
    def test_different_pred_lens(self):
        """æµ‹è¯•ä¸åŒé¢„æµ‹é•¿åº¦"""
        for pred_len in [24, 48, 96, 192, 336, 720]:
            head = self._create_head(target_window=pred_len)
            x = self._create_input()
            
            output = head(x)
            
            expected_shape = (self.batch_size, pred_len, self.n_vars)
            self.assertEqual(output.shape, expected_shape, f"pred_len={pred_len} å¤±è´¥")
        
        print("âœ… TriBandDecoupledHead ä¸åŒé¢„æµ‹é•¿åº¦æµ‹è¯•é€šè¿‡")
    
    def test_different_batch_sizes(self):
        """æµ‹è¯•ä¸åŒæ‰¹æ¬¡å¤§å°"""
        head = self._create_head()
        
        for batch_size in [1, 2, 8, 16, 32]:
            x = torch.randn(
                batch_size, self.n_vars, self.d_ff, self.patch_nums,
                device=self.device
            )
            output = head(x)
            
            expected_shape = (batch_size, self.pred_len, self.n_vars)
            self.assertEqual(output.shape, expected_shape, f"batch_size={batch_size} å¤±è´¥")
        
        print("âœ… TriBandDecoupledHead ä¸åŒæ‰¹æ¬¡å¤§å°æµ‹è¯•é€šè¿‡")
    
    def test_parameter_count(self):
        """æµ‹è¯•å‚æ•°ç»Ÿè®¡"""
        head = self._create_head()
        
        total_params = sum(p.numel() for p in head.parameters())
        trainable_params = sum(p.numel() for p in head.parameters() if p.requires_grad)
        
        self.assertEqual(total_params, trainable_params)
        self.assertGreater(total_params, 0)
        
        print(f"âœ… TriBandDecoupledHead å‚æ•°ç»Ÿè®¡: {total_params:,} å‚æ•°")


class TestDeepSupervisionLoss(unittest.TestCase):
    """DeepSupervisionLoss æ¨¡å—æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        self.batch_size = 4
        self.n_vars = 7
        self.pred_len = 96
    
    def _create_loss_fn(self, **kwargs) -> DeepSupervisionLoss:
        """åˆ›å»ºæµ‹è¯•ç”¨çš„ Loss å‡½æ•°"""
        default_kwargs = {
            'wavelet': 'db4',
            'level': 2,
            'alpha': 0.3,
            'use_causal_swt': True,  # ä½¿ç”¨å› æœç‰ˆæœ¬ç¡®ä¿æµ‹è¯•é€šè¿‡
        }
        default_kwargs.update(kwargs)
        return DeepSupervisionLoss(**default_kwargs).to(self.device)
    
    def _create_pred_and_target(self) -> Tuple[torch.Tensor, torch.Tensor]:
        """åˆ›å»ºé¢„æµ‹å’Œç›®æ ‡"""
        pred = torch.randn(self.batch_size, self.pred_len, self.n_vars, device=self.device)
        target = torch.randn(self.batch_size, self.pred_len, self.n_vars, device=self.device)
        return pred, target
    
    def _create_components(self) -> Dict[str, torch.Tensor]:
        """åˆ›å»ºé¢‘ç‡åˆ†é‡"""
        shape = (self.batch_size, self.pred_len, self.n_vars)
        return {
            'pred_trend': torch.randn(*shape, device=self.device),
            'pred_mid': torch.randn(*shape, device=self.device),
            'pred_detail': torch.randn(*shape, device=self.device),
        }
    
    def test_basic_loss_computation(self):
        """æµ‹è¯•åŸºæœ¬æŸå¤±è®¡ç®—"""
        ds_loss = self._create_loss_fn()
        pred, target = self._create_pred_and_target()
        components = self._create_components()
        
        total_loss, loss_dict = ds_loss(pred, target, components)
        
        # æ£€æŸ¥è¿”å›å€¼
        self.assertIsInstance(total_loss, torch.Tensor)
        self.assertIsInstance(loss_dict, dict)
        
        # æ£€æŸ¥æŸå¤±å­—å…¸å†…å®¹
        self.assertIn('main_loss', loss_dict)
        self.assertIn('loss_trend', loss_dict)
        self.assertIn('loss_mid', loss_dict)
        self.assertIn('loss_detail', loss_dict)
        self.assertIn('aux_loss', loss_dict)
        self.assertIn('total_loss', loss_dict)
        
        print("âœ… DeepSupervisionLoss åŸºæœ¬æŸå¤±è®¡ç®—æµ‹è¯•é€šè¿‡")
    
    def test_loss_without_components(self):
        """æµ‹è¯•æ— åˆ†é‡æ—¶åªè¿”å›ä¸»æŸå¤±"""
        ds_loss = self._create_loss_fn()
        pred, target = self._create_pred_and_target()
        
        total_loss, loss_dict = ds_loss(pred, target, components=None)
        
        # åº”è¯¥åªæœ‰ä¸»æŸå¤±
        self.assertIn('main_loss', loss_dict)
        self.assertNotIn('aux_loss', loss_dict)
        
        # æ€»æŸå¤±åº”ç­‰äºä¸»æŸå¤±
        main_loss = F.mse_loss(pred, target)
        self.assertAlmostEqual(total_loss.item(), main_loss.item(), places=5)
        
        print("âœ… DeepSupervisionLoss æ— åˆ†é‡æ¨¡å¼æµ‹è¯•é€šè¿‡")
    
    def test_alpha_weighting(self):
        """æµ‹è¯• alpha æƒé‡"""
        pred, target = self._create_pred_and_target()
        components = self._create_components()
        
        # æµ‹è¯•ä¸åŒ alpha å€¼
        for alpha in [0.0, 0.1, 0.3, 0.5, 1.0]:
            ds_loss = self._create_loss_fn(alpha=alpha)
            total_loss, loss_dict = ds_loss(pred, target, components)
            
            # éªŒè¯å…¬å¼: total = main + alpha * aux
            expected_total = loss_dict['main_loss'] + alpha * loss_dict['aux_loss']
            self.assertAlmostEqual(
                loss_dict['total_loss'], expected_total, places=5,
                msg=f"alpha={alpha} æ—¶æŸå¤±è®¡ç®—é”™è¯¯"
            )
        
        print("âœ… DeepSupervisionLoss alpha æƒé‡æµ‹è¯•é€šè¿‡")
    
    def test_gradient_flow(self):
        """æµ‹è¯•æ¢¯åº¦ä¼ æ’­"""
        ds_loss = self._create_loss_fn()
        
        pred = torch.randn(
            self.batch_size, self.pred_len, self.n_vars,
            device=self.device, requires_grad=True
        )
        target = torch.randn(self.batch_size, self.pred_len, self.n_vars, device=self.device)
        
        components = {
            'pred_trend': torch.randn(
                self.batch_size, self.pred_len, self.n_vars,
                device=self.device, requires_grad=True
            ),
            'pred_mid': torch.randn(
                self.batch_size, self.pred_len, self.n_vars,
                device=self.device, requires_grad=True
            ),
            'pred_detail': torch.randn(
                self.batch_size, self.pred_len, self.n_vars,
                device=self.device, requires_grad=True
            ),
        }
        
        total_loss, _ = ds_loss(pred, target, components)
        total_loss.backward()
        
        # æ£€æŸ¥æ¢¯åº¦
        self.assertIsNotNone(pred.grad)
        for key, comp in components.items():
            self.assertIsNotNone(comp.grad, f"{key} æ²¡æœ‰æ¢¯åº¦")
        
        print("âœ… DeepSupervisionLoss æ¢¯åº¦ä¼ æ’­æµ‹è¯•é€šè¿‡")
    
    def test_different_wavelet_levels(self):
        """æµ‹è¯•ä¸åŒå°æ³¢åˆ†è§£å±‚æ•°"""
        pred, target = self._create_pred_and_target()
        
        for level in [1, 2, 3]:
            ds_loss = self._create_loss_fn(level=level)
            components = self._create_components()
            
            total_loss, loss_dict = ds_loss(pred, target, components)
            
            self.assertIsInstance(total_loss, torch.Tensor)
            self.assertFalse(torch.isnan(total_loss))
        
        print("âœ… DeepSupervisionLoss ä¸åŒå°æ³¢å±‚æ•°æµ‹è¯•é€šè¿‡")


class TestIntegration(unittest.TestCase):
    """é›†æˆæµ‹è¯•ï¼šTriBandDecoupledHead + DeepSupervisionLoss"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
        self.batch_size = 4
        self.n_vars = 7
        self.d_ff = 32
        self.patch_nums = 10
        self.nf = self.d_ff * self.patch_nums
        self.pred_len = 96
    
    def test_end_to_end_training_step(self):
        """æµ‹è¯•ç«¯åˆ°ç«¯è®­ç»ƒæ­¥éª¤"""
        # åˆ›å»ºæ¨¡å—
        head = TriBandDecoupledHead(
            n_vars=self.n_vars,
            nf=self.nf,
            target_window=self.pred_len,
            use_soft_threshold=True,
        ).to(self.device)
        
        ds_loss = DeepSupervisionLoss(
            wavelet='db4',
            level=2,
            alpha=0.3,
            use_causal_swt=True,
        ).to(self.device)
        
        optimizer = torch.optim.Adam(head.parameters(), lr=1e-3)
        
        # æ¨¡æ‹Ÿè®­ç»ƒ
        head.train()
        for step in range(5):
            # åˆ›å»ºè¾“å…¥å’Œç›®æ ‡
            x = torch.randn(
                self.batch_size, self.n_vars, self.d_ff, self.patch_nums,
                device=self.device
            )
            target = torch.randn(
                self.batch_size, self.pred_len, self.n_vars,
                device=self.device
            )
            
            # å‰å‘ä¼ æ’­
            pred, components = head(x, return_components=True)
            
            # è®¡ç®—æŸå¤±
            loss, loss_dict = ds_loss(pred, target, components)
            
            # åå‘ä¼ æ’­
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            # æ£€æŸ¥æŸå¤±æœ‰æ•ˆ
            self.assertFalse(torch.isnan(loss))
            self.assertFalse(torch.isinf(loss))
        
        print("âœ… ç«¯åˆ°ç«¯è®­ç»ƒæ­¥éª¤æµ‹è¯•é€šè¿‡")
    
    def test_loss_decreases_during_training(self):
        """æµ‹è¯•è®­ç»ƒè¿‡ç¨‹ä¸­æŸå¤±ä¸‹é™"""
        # åˆ›å»ºæ¨¡å—
        head = TriBandDecoupledHead(
            n_vars=self.n_vars,
            nf=self.nf,
            target_window=self.pred_len,
            use_soft_threshold=True,
        ).to(self.device)
        
        ds_loss = DeepSupervisionLoss(
            wavelet='db4',
            level=2,
            alpha=0.3,
            use_causal_swt=True,
        ).to(self.device)
        
        optimizer = torch.optim.Adam(head.parameters(), lr=1e-2)
        
        # å›ºå®šè¾“å…¥å’Œç›®æ ‡
        x = torch.randn(
            self.batch_size, self.n_vars, self.d_ff, self.patch_nums,
            device=self.device
        )
        target = torch.randn(
            self.batch_size, self.pred_len, self.n_vars,
            device=self.device
        )
        
        # è®­ç»ƒå¹¶è®°å½•æŸå¤±
        losses = []
        head.train()
        for _ in range(50):
            pred, components = head(x, return_components=True)
            loss, _ = ds_loss(pred, target, components)
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            losses.append(loss.item())
        
        # æ£€æŸ¥æŸå¤±ä¸‹é™è¶‹åŠ¿
        first_10_avg = np.mean(losses[:10])
        last_10_avg = np.mean(losses[-10:])
        
        self.assertLess(last_10_avg, first_10_avg, "æŸå¤±æœªä¸‹é™")
        print(f"âœ… æŸå¤±ä¸‹é™æµ‹è¯•é€šè¿‡: {first_10_avg:.4f} -> {last_10_avg:.4f}")
    
    def test_eval_mode_deterministic(self):
        """æµ‹è¯• eval æ¨¡å¼è¾“å‡ºç¡®å®šæ€§"""
        head = TriBandDecoupledHead(
            n_vars=self.n_vars,
            nf=self.nf,
            target_window=self.pred_len,
        ).to(self.device)
        
        head.eval()
        x = torch.randn(
            self.batch_size, self.n_vars, self.d_ff, self.patch_nums,
            device=self.device
        )
        
        with torch.no_grad():
            output1 = head(x)
            output2 = head(x)
        
        self.assertTrue(torch.allclose(output1, output2))
        print("âœ… eval æ¨¡å¼ç¡®å®šæ€§æµ‹è¯•é€šè¿‡")


class TestPerformance(unittest.TestCase):
    """æ€§èƒ½æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    
    def test_inference_speed(self):
        """æµ‹è¯•æ¨ç†é€Ÿåº¦"""
        batch_size = 32
        n_vars = 7
        d_ff = 32
        patch_nums = 10
        nf = d_ff * patch_nums
        pred_len = 96
        
        head = TriBandDecoupledHead(
            n_vars=n_vars,
            nf=nf,
            target_window=pred_len,
        ).to(self.device)
        head.eval()
        
        x = torch.randn(batch_size, n_vars, d_ff, patch_nums, device=self.device)
        
        # é¢„çƒ­
        with torch.no_grad():
            for _ in range(10):
                _ = head(x)
        
        # è®¡æ—¶
        if self.device.type == 'cuda':
            torch.cuda.synchronize()
        
        start_time = time.time()
        num_iterations = 100
        
        with torch.no_grad():
            for _ in range(num_iterations):
                _ = head(x)
        
        if self.device.type == 'cuda':
            torch.cuda.synchronize()
        
        elapsed_time = time.time() - start_time
        avg_time = elapsed_time / num_iterations * 1000  # ms
        
        print(f"âœ… æ¨ç†é€Ÿåº¦æµ‹è¯•: {avg_time:.3f} ms/batch (batch_size={batch_size})")
    
    def test_memory_usage(self):
        """æµ‹è¯•æ˜¾å­˜ä½¿ç”¨"""
        if self.device.type != 'cuda':
            self.skipTest("éœ€è¦ CUDA è®¾å¤‡")
        
        batch_size = 32
        n_vars = 7
        d_ff = 32
        patch_nums = 10
        nf = d_ff * patch_nums
        pred_len = 96
        
        torch.cuda.reset_peak_memory_stats()
        
        head = TriBandDecoupledHead(
            n_vars=n_vars,
            nf=nf,
            target_window=pred_len,
        ).to(self.device)
        
        x = torch.randn(batch_size, n_vars, d_ff, patch_nums, device=self.device)
        
        # å‰å‘ä¼ æ’­
        output, components = head(x, return_components=True)
        
        # åå‘ä¼ æ’­
        loss = output.sum()
        loss.backward()
        
        peak_memory = torch.cuda.max_memory_allocated() / 1024 / 1024  # MB
        
        print(f"âœ… æ˜¾å­˜ä½¿ç”¨æµ‹è¯•: {peak_memory:.2f} MB (batch_size={batch_size})")


class TestEdgeCases(unittest.TestCase):
    """è¾¹ç•Œæ¡ä»¶æµ‹è¯•"""
    
    def setUp(self):
        """æµ‹è¯•åˆå§‹åŒ–"""
        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    
    def test_single_variable(self):
        """æµ‹è¯•å•å˜é‡æƒ…å†µ"""
        head = TriBandDecoupledHead(
            n_vars=1,
            nf=320,
            target_window=96,
        ).to(self.device)
        
        x = torch.randn(4, 1, 32, 10, device=self.device)
        output = head(x)
        
        self.assertEqual(output.shape, (4, 96, 1))
        print("âœ… å•å˜é‡æµ‹è¯•é€šè¿‡")
    
    def test_single_batch(self):
        """æµ‹è¯•å•æ‰¹æ¬¡æƒ…å†µ"""
        head = TriBandDecoupledHead(
            n_vars=7,
            nf=320,
            target_window=96,
        ).to(self.device)
        
        x = torch.randn(1, 7, 32, 10, device=self.device)
        output = head(x)
        
        self.assertEqual(output.shape, (1, 96, 7))
        print("âœ… å•æ‰¹æ¬¡æµ‹è¯•é€šè¿‡")
    
    def test_very_short_prediction(self):
        """æµ‹è¯•æçŸ­é¢„æµ‹é•¿åº¦"""
        head = TriBandDecoupledHead(
            n_vars=7,
            nf=320,
            target_window=1,
        ).to(self.device)
        
        x = torch.randn(4, 7, 32, 10, device=self.device)
        output = head(x)
        
        self.assertEqual(output.shape, (4, 1, 7))
        print("âœ… æçŸ­é¢„æµ‹é•¿åº¦æµ‹è¯•é€šè¿‡")
    
    def test_very_long_prediction(self):
        """æµ‹è¯•æé•¿é¢„æµ‹é•¿åº¦"""
        head = TriBandDecoupledHead(
            n_vars=7,
            nf=320,
            target_window=720,
        ).to(self.device)
        
        x = torch.randn(4, 7, 32, 10, device=self.device)
        output = head(x)
        
        self.assertEqual(output.shape, (4, 720, 7))
        print("âœ… æé•¿é¢„æµ‹é•¿åº¦æµ‹è¯•é€šè¿‡")
    
    def test_zero_dropout(self):
        """æµ‹è¯•é›¶ Dropout"""
        head = TriBandDecoupledHead(
            n_vars=7,
            nf=320,
            target_window=96,
            head_dropout=0.0,
            mid_dropout=0.0,
            high_dropout=0.0,
        ).to(self.device)
        
        x = torch.randn(4, 7, 32, 10, device=self.device)
        output = head(x)
        
        self.assertEqual(output.shape, (4, 96, 7))
        print("âœ… é›¶ Dropout æµ‹è¯•é€šè¿‡")
    
    def test_high_dropout(self):
        """æµ‹è¯•é«˜ Dropout"""
        head = TriBandDecoupledHead(
            n_vars=7,
            nf=320,
            target_window=96,
            head_dropout=0.9,
            mid_dropout=0.9,
            high_dropout=0.9,
        ).to(self.device)
        
        x = torch.randn(4, 7, 32, 10, device=self.device)
        output = head(x)
        
        self.assertEqual(output.shape, (4, 96, 7))
        self.assertFalse(torch.isnan(output).any())
        print("âœ… é«˜ Dropout æµ‹è¯•é€šè¿‡")


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 70)
    print("é¢‘ç‡è§£è€¦è¾“å‡ºå¤´ (Frequency Decoupled Head) å…¨é¢æµ‹è¯•")
    print("=" * 70)
    
    # åˆ›å»ºæµ‹è¯•å¥—ä»¶
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()
    
    # æ·»åŠ æµ‹è¯•ç±»
    suite.addTests(loader.loadTestsFromTestCase(TestSoftThreshold))
    suite.addTests(loader.loadTestsFromTestCase(TestTriBandDecoupledHead))
    suite.addTests(loader.loadTestsFromTestCase(TestDeepSupervisionLoss))
    suite.addTests(loader.loadTestsFromTestCase(TestIntegration))
    suite.addTests(loader.loadTestsFromTestCase(TestPerformance))
    suite.addTests(loader.loadTestsFromTestCase(TestEdgeCases))
    
    # è¿è¡Œæµ‹è¯•
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)
    
    # æ‰“å°æ€»ç»“
    print("\n" + "=" * 70)
    if result.wasSuccessful():
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    else:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {len(result.failures)} å¤±è´¥, {len(result.errors)} é”™è¯¯")
    print("=" * 70)
    
    return result.wasSuccessful()


if __name__ == "__main__":
    success = run_all_tests()
    sys.exit(0 if success else 1)

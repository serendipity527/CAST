#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
MLPæ˜ å°„å±‚æµ‹è¯•è„šæœ¬

æµ‹è¯•å†…å®¹ï¼š
1. MLPæ˜ å°„å±‚çš„æ­£ç¡®åˆå§‹åŒ–
2. ç»´åº¦æ£€æŸ¥
3. å‰å‘ä¼ æ’­æµ‹è¯•
4. å‚æ•°é‡éªŒè¯
5. ä¸Linearå±‚çš„å¯¹æ¯”
6. æ¢¯åº¦æµæµ‹è¯•
7. éçº¿æ€§æ¿€æ´»éªŒè¯
"""

import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import torch
import torch.nn as nn
from transformers import GPT2Tokenizer, GPT2Model

from models.TimeLLM import Model


class TestConfig:
    """æµ‹è¯•é…ç½®ç±»"""
    def __init__(self):
        # åŸºç¡€é…ç½®
        self.task_name = 'long_term_forecast'
        self.llm_model = 'GPT2'
        self.llm_dim = 768
        self.llm_layers = 2
        self.d_model = 16
        self.n_heads = 4
        self.d_ff = 32
        self.dropout = 0.1
        self.patch_len = 16
        self.stride = 8
        self.seq_len = 96
        self.pred_len = 96
        self.enc_in = 7
        self.dec_in = 7
        self.c_out = 7
        
        # å°æ³¢é…ç½®
        self.wavelet_mode = 'wist'
        self.wavelet_type = 'haar'
        self.wavelet_level = 2
        
        # åˆ†ç¦»åŸå‹é…ç½®
        self.use_dual_prototypes = 1
        self.dual_proto_trend_tokens = 1000
        self.dual_proto_detail_tokens = 1000
        self.dual_proto_fusion_method = 'weighted'
        
        # è¯­ä¹‰ç­›é€‰æ˜ å°„é…ç½®
        self.use_semantic_filtered_mapping = 1
        self.dual_proto_trend_seed_words = 1000
        self.dual_proto_detail_seed_words = 1000
        self.dual_proto_seed_semantic_filter = 1
        
        # MLPæ˜ å°„å±‚é…ç½®ï¼ˆç­–ç•¥ä¸€ï¼‰
        self.dual_proto_mlp_hidden_dim = 4096
        self.dual_proto_mlp_dropout = 0.1
        
        # Prompté…ç½®
        self.prompt_domain = 0
        self.content = 'Test dataset description'
        
        # å…¶ä»–é…ç½®
        self.use_cwpr = 0
        self.use_dual_scale_head = 0
        self.use_freq_decoupled_head = 0


def test_mlp_mapping_initialization():
    """æµ‹è¯•1: MLPæ˜ å°„å±‚åˆå§‹åŒ–"""
    print("=" * 70)
    print("æµ‹è¯•1: MLPæ˜ å°„å±‚åˆå§‹åŒ–")
    print("=" * 70)
    
    configs = TestConfig()
    
    try:
        model = Model(configs)
        print("âœ… æ¨¡å‹åˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    # æ£€æŸ¥æ˜ å°„å±‚ç±»å‹
    print("\n[æ£€æŸ¥1] æ˜ å°„å±‚ç±»å‹...")
    if not isinstance(model.trend_mapping, nn.Sequential):
        print(f"âŒ trend_mapping ä¸æ˜¯ Sequentialï¼Œè€Œæ˜¯ {type(model.trend_mapping)}")
        return False
    print("âœ… trend_mapping æ˜¯ Sequential (MLP)")
    
    if not isinstance(model.detail_mapping, nn.Sequential):
        print(f"âŒ detail_mapping ä¸æ˜¯ Sequentialï¼Œè€Œæ˜¯ {type(model.detail_mapping)}")
        return False
    print("âœ… detail_mapping æ˜¯ Sequential (MLP)")
    
    # æ£€æŸ¥MLPç»“æ„
    print("\n[æ£€æŸ¥2] MLPç»“æ„...")
    trend_modules = list(model.trend_mapping.modules())[1:]  # è·³è¿‡Sequentialæœ¬èº«
    detail_modules = list(model.detail_mapping.modules())[1:]
    
    expected_structure = [nn.Linear, nn.GELU, nn.Dropout, nn.Linear]
    for i, (trend_mod, detail_mod, expected_type) in enumerate(zip(trend_modules, detail_modules, expected_structure)):
        if not isinstance(trend_mod, expected_type):
            print(f"âŒ trend_mapping ç¬¬{i+1}å±‚ä¸æ˜¯ {expected_type.__name__}ï¼Œè€Œæ˜¯ {type(trend_mod).__name__}")
            return False
        if not isinstance(detail_mod, expected_type):
            print(f"âŒ detail_mapping ç¬¬{i+1}å±‚ä¸æ˜¯ {expected_type.__name__}ï¼Œè€Œæ˜¯ {type(detail_mod).__name__}")
            return False
    
    print("âœ… MLPç»“æ„æ­£ç¡®: Linear -> GELU -> Dropout -> Linear")
    
    return True


def test_mlp_mapping_dimensions():
    """æµ‹è¯•2: MLPæ˜ å°„å±‚ç»´åº¦æ£€æŸ¥"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•2: MLPæ˜ å°„å±‚ç»´åº¦æ£€æŸ¥")
    print("=" * 70)
    
    configs = TestConfig()
    model = Model(configs)
    
    # è·å–ç§å­è¯æ•°é‡
    num_trend_seeds = model.trend_seed_embeddings.shape[0]
    num_detail_seeds = model.detail_seed_embeddings.shape[0]
    d_llm = model.d_llm
    
    print(f"\nç§å­è¯é…ç½®:")
    print(f"  - è¶‹åŠ¿ç§å­è¯: {num_trend_seeds} ä¸ª")
    print(f"  - ç»†èŠ‚ç§å­è¯: {num_detail_seeds} ä¸ª")
    print(f"  - LLMç»´åº¦: {d_llm}")
    
    # æ£€æŸ¥ç¬¬ä¸€å±‚Linearçš„è¾“å…¥ç»´åº¦
    trend_first_linear = model.trend_mapping[0]
    detail_first_linear = model.detail_mapping[0]
    
    print(f"\n[æ£€æŸ¥1] ç¬¬ä¸€å±‚Linearè¾“å…¥ç»´åº¦...")
    if trend_first_linear.in_features != num_trend_seeds:
        print(f"âŒ trend_mapping ç¬¬ä¸€å±‚è¾“å…¥ç»´åº¦ä¸åŒ¹é…: {trend_first_linear.in_features} != {num_trend_seeds}")
        return False
    print(f"âœ… trend_mapping ç¬¬ä¸€å±‚è¾“å…¥ç»´åº¦: {trend_first_linear.in_features}")
    
    if detail_first_linear.in_features != num_detail_seeds:
        print(f"âŒ detail_mapping ç¬¬ä¸€å±‚è¾“å…¥ç»´åº¦ä¸åŒ¹é…: {detail_first_linear.in_features} != {num_detail_seeds}")
        return False
    print(f"âœ… detail_mapping ç¬¬ä¸€å±‚è¾“å…¥ç»´åº¦: {detail_first_linear.in_features}")
    
    # æ£€æŸ¥éšè—å±‚ç»´åº¦
    mlp_hidden_dim = configs.dual_proto_mlp_hidden_dim
    print(f"\n[æ£€æŸ¥2] éšè—å±‚ç»´åº¦...")
    if trend_first_linear.out_features != mlp_hidden_dim:
        print(f"âŒ trend_mapping éšè—å±‚ç»´åº¦ä¸åŒ¹é…: {trend_first_linear.out_features} != {mlp_hidden_dim}")
        return False
    print(f"âœ… trend_mapping éšè—å±‚ç»´åº¦: {trend_first_linear.out_features}")
    
    if detail_first_linear.out_features != mlp_hidden_dim:
        print(f"âŒ detail_mapping éšè—å±‚ç»´åº¦ä¸åŒ¹é…: {detail_first_linear.out_features} != {mlp_hidden_dim}")
        return False
    print(f"âœ… detail_mapping éšè—å±‚ç»´åº¦: {detail_first_linear.out_features}")
    
    # æ£€æŸ¥æœ€åä¸€å±‚Linearçš„è¾“å‡ºç»´åº¦
    trend_last_linear = model.trend_mapping[3]
    detail_last_linear = model.detail_mapping[3]
    
    print(f"\n[æ£€æŸ¥3] æœ€åä¸€å±‚Linearè¾“å‡ºç»´åº¦...")
    if trend_last_linear.out_features != model.num_trend_tokens:
        print(f"âŒ trend_mapping è¾“å‡ºç»´åº¦ä¸åŒ¹é…: {trend_last_linear.out_features} != {model.num_trend_tokens}")
        return False
    print(f"âœ… trend_mapping è¾“å‡ºç»´åº¦: {trend_last_linear.out_features}")
    
    if detail_last_linear.out_features != model.num_detail_tokens:
        print(f"âŒ detail_mapping è¾“å‡ºç»´åº¦ä¸åŒ¹é…: {detail_last_linear.out_features} != {model.num_detail_tokens}")
        return False
    print(f"âœ… detail_mapping è¾“å‡ºç»´åº¦: {detail_last_linear.out_features}")
    
    return True


def test_mlp_mapping_forward():
    """æµ‹è¯•3: MLPæ˜ å°„å±‚å‰å‘ä¼ æ’­"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•3: MLPæ˜ å°„å±‚å‰å‘ä¼ æ’­")
    print("=" * 70)
    
    configs = TestConfig()
    model = Model(configs)
    model.eval()
    
    # è·å–ç§å­è¯embeddings
    trend_seed_emb = model.trend_seed_embeddings  # (num_trend_seeds, d_llm)
    detail_seed_emb = model.detail_seed_embeddings  # (num_detail_seeds, d_llm)
    
    print(f"\nè¾“å…¥å½¢çŠ¶:")
    print(f"  - trend_seed_embeddings: {trend_seed_emb.shape}")
    print(f"  - detail_seed_embeddings: {detail_seed_emb.shape}")
    
    # å‰å‘ä¼ æ’­ï¼ˆä¸æ¨¡å‹forwardä¸­çš„é€»è¾‘ä¸€è‡´ï¼‰
    with torch.no_grad():
        # è½¬ç½®: (num_seeds, d_llm) -> (d_llm, num_seeds)
        trend_input = trend_seed_emb.permute(1, 0)  # (d_llm, num_trend_seeds)
        detail_input = detail_seed_emb.permute(1, 0)  # (d_llm, num_detail_seeds)
        
        print(f"\nè½¬ç½®åå½¢çŠ¶:")
        print(f"  - trend_input: {trend_input.shape}")
        print(f"  - detail_input: {detail_input.shape}")
        
        # MLPæ˜ å°„
        trend_output = model.trend_mapping(trend_input)  # (d_llm, num_trend_tokens)
        detail_output = model.detail_mapping(detail_input)  # (d_llm, num_detail_tokens)
        
        print(f"\nMLPè¾“å‡ºå½¢çŠ¶:")
        print(f"  - trend_output: {trend_output.shape}")
        print(f"  - detail_output: {detail_output.shape}")
        
        # è½¬ç½®å›: (d_llm, num_tokens) -> (num_tokens, d_llm)
        trend_prototypes = trend_output.permute(1, 0)  # (num_trend_tokens, d_llm)
        detail_prototypes = detail_output.permute(1, 0)  # (num_detail_tokens, d_llm)
        
        print(f"\næœ€ç»ˆåŸå‹å½¢çŠ¶:")
        print(f"  - trend_prototypes: {trend_prototypes.shape}")
        print(f"  - detail_prototypes: {detail_prototypes.shape}")
    
    # éªŒè¯è¾“å‡ºç»´åº¦
    if trend_prototypes.shape != (model.num_trend_tokens, model.d_llm):
        print(f"âŒ trend_prototypes å½¢çŠ¶ä¸æ­£ç¡®: {trend_prototypes.shape} != ({model.num_trend_tokens}, {model.d_llm})")
        return False
    print("âœ… trend_prototypes å½¢çŠ¶æ­£ç¡®")
    
    if detail_prototypes.shape != (model.num_detail_tokens, model.d_llm):
        print(f"âŒ detail_prototypes å½¢çŠ¶ä¸æ­£ç¡®: {detail_prototypes.shape} != ({model.num_detail_tokens}, {model.d_llm})")
        return False
    print("âœ… detail_prototypes å½¢çŠ¶æ­£ç¡®")
    
    # æ£€æŸ¥è¾“å‡ºå€¼æ˜¯å¦åˆç†ï¼ˆä¸åº”è¯¥å…¨æ˜¯0æˆ–NaNï¼‰
    if torch.isnan(trend_prototypes).any() or torch.isnan(detail_prototypes).any():
        print("âŒ è¾“å‡ºåŒ…å«NaNå€¼")
        return False
    print("âœ… è¾“å‡ºå€¼åˆç†ï¼ˆæ— NaNï¼‰")
    
    if (trend_prototypes == 0).all() or (detail_prototypes == 0).all():
        print("âš ï¸  è­¦å‘Š: è¾“å‡ºå…¨ä¸º0ï¼Œå¯èƒ½åˆå§‹åŒ–æœ‰é—®é¢˜")
    else:
        print("âœ… è¾“å‡ºå€¼éé›¶")
    
    return True


def test_mlp_mapping_parameters():
    """æµ‹è¯•4: MLPæ˜ å°„å±‚å‚æ•°é‡"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•4: MLPæ˜ å°„å±‚å‚æ•°é‡")
    print("=" * 70)
    
    configs = TestConfig()
    model = Model(configs)
    
    # è®¡ç®—å‚æ•°é‡
    trend_params = sum(p.numel() for p in model.trend_mapping.parameters())
    detail_params = sum(p.numel() for p in model.detail_mapping.parameters())
    total_params = trend_params + detail_params
    
    print(f"\nå‚æ•°é‡ç»Ÿè®¡:")
    print(f"  - trend_mapping: {trend_params:,} ({trend_params/1e6:.2f}M)")
    print(f"  - detail_mapping: {detail_params:,} ({detail_params/1e6:.2f}M)")
    print(f"  - æ€»è®¡: {total_params:,} ({total_params/1e6:.2f}M)")
    
    # æ‰‹åŠ¨è®¡ç®—é¢„æœŸå‚æ•°é‡
    num_trend_seeds = model.trend_seed_embeddings.shape[0]
    num_detail_seeds = model.detail_seed_embeddings.shape[0]
    mlp_hidden_dim = configs.dual_proto_mlp_hidden_dim
    
    expected_trend_params = (
        num_trend_seeds * mlp_hidden_dim + mlp_hidden_dim +  # ç¬¬ä¸€å±‚Linear + bias
        mlp_hidden_dim * model.num_trend_tokens + model.num_trend_tokens  # ç¬¬äºŒå±‚Linear + bias
    )
    
    expected_detail_params = (
        num_detail_seeds * mlp_hidden_dim + mlp_hidden_dim +  # ç¬¬ä¸€å±‚Linear + bias
        mlp_hidden_dim * model.num_detail_tokens + model.num_detail_tokens  # ç¬¬äºŒå±‚Linear + bias
    )
    
    print(f"\né¢„æœŸå‚æ•°é‡:")
    print(f"  - trend_mapping: {expected_trend_params:,} ({expected_trend_params/1e6:.2f}M)")
    print(f"  - detail_mapping: {expected_detail_params:,} ({expected_detail_params/1e6:.2f}M)")
    
    # éªŒè¯å‚æ•°é‡ï¼ˆå…è®¸å°çš„å·®å¼‚ï¼Œå› ä¸ºå¯èƒ½æœ‰å…¶ä»–å‚æ•°ï¼‰
    if abs(trend_params - expected_trend_params) > 10:
        print(f"âš ï¸  è­¦å‘Š: trend_mapping å‚æ•°é‡å·®å¼‚è¾ƒå¤§: {abs(trend_params - expected_trend_params)}")
    else:
        print("âœ… trend_mapping å‚æ•°é‡æ­£ç¡®")
    
    if abs(detail_params - expected_detail_params) > 10:
        print(f"âš ï¸  è­¦å‘Š: detail_mapping å‚æ•°é‡å·®å¼‚è¾ƒå¤§: {abs(detail_params - expected_detail_params)}")
    else:
        print("âœ… detail_mapping å‚æ•°é‡æ­£ç¡®")
    
    # å¯¹æ¯”Linearç‰ˆæœ¬
    linear_params = num_trend_seeds * model.num_trend_tokens + num_detail_seeds * model.num_detail_tokens
    print(f"\nå¯¹æ¯”Linearç‰ˆæœ¬:")
    print(f"  - Linearç‰ˆæœ¬å‚æ•°é‡: {linear_params:,} ({linear_params/1e6:.2f}M)")
    print(f"  - MLPç‰ˆæœ¬å‚æ•°é‡: {total_params:,} ({total_params/1e6:.2f}M)")
    print(f"  - å¢åŠ å€æ•°: {total_params / linear_params:.2f}x")
    
    return True


def test_mlp_mapping_gradients():
    """æµ‹è¯•5: MLPæ˜ å°„å±‚æ¢¯åº¦æµ"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•5: MLPæ˜ å°„å±‚æ¢¯åº¦æµ")
    print("=" * 70)
    
    configs = TestConfig()
    model = Model(configs)
    model.train()
    
    # åˆ›å»ºè™šæ‹Ÿè¾“å…¥
    batch_size = 2
    x_enc = torch.randn(batch_size, configs.seq_len, configs.enc_in)
    x_mark_enc = torch.zeros(batch_size, configs.seq_len, 4)
    x_dec = torch.randn(batch_size, configs.pred_len, configs.enc_in)
    x_mark_dec = torch.zeros(batch_size, configs.pred_len, 4)
    
    # å‰å‘ä¼ æ’­
    output = model(x_enc, x_mark_enc, x_dec, x_mark_dec)
    
    # åˆ›å»ºè™šæ‹ŸæŸå¤±
    target = torch.randn_like(output)
    loss = nn.MSELoss()(output, target)
    
    # åå‘ä¼ æ’­
    loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    print("\n[æ£€æŸ¥1] æ˜ å°„å±‚å‚æ•°æ¢¯åº¦...")
    trend_has_grad = any(p.grad is not None and p.grad.abs().sum() > 0 for p in model.trend_mapping.parameters())
    detail_has_grad = any(p.grad is not None and p.grad.abs().sum() > 0 for p in model.detail_mapping.parameters())
    
    if not trend_has_grad:
        print("âŒ trend_mapping æ²¡æœ‰æ¢¯åº¦")
        return False
    print("âœ… trend_mapping æœ‰æ¢¯åº¦")
    
    if not detail_has_grad:
        print("âŒ detail_mapping æ²¡æœ‰æ¢¯åº¦")
        return False
    print("âœ… detail_mapping æœ‰æ¢¯åº¦")
    
    # æ£€æŸ¥Bufferä¸å‚ä¸æ¢¯åº¦æ›´æ–°
    print("\n[æ£€æŸ¥2] Bufferä¸å‚ä¸æ¢¯åº¦æ›´æ–°...")
    if model.trend_seed_embeddings.requires_grad:
        print("âŒ trend_seed_embeddings requires_grad=Trueï¼ˆåº”è¯¥æ˜¯Falseï¼‰")
        return False
    print("âœ… trend_seed_embeddings requires_grad=False")
    
    if model.detail_seed_embeddings.requires_grad:
        print("âŒ detail_seed_embeddings requires_grad=Trueï¼ˆåº”è¯¥æ˜¯Falseï¼‰")
        return False
    print("âœ… detail_seed_embeddings requires_grad=False")
    
    return True


def test_mlp_vs_linear_comparison():
    """æµ‹è¯•6: MLP vs Linearå¯¹æ¯”"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•6: MLP vs Linearå¯¹æ¯”")
    print("=" * 70)
    
    configs = TestConfig()
    
    # åˆ›å»ºMLPç‰ˆæœ¬æ¨¡å‹
    model_mlp = Model(configs)
    model_mlp.eval()
    
    # åˆ›å»ºLinearç‰ˆæœ¬æ¨¡å‹ï¼ˆé€šè¿‡ä¿®æ”¹é…ç½®ï¼‰
    configs_linear = TestConfig()
    # è¿™é‡Œæˆ‘ä»¬éœ€è¦æ‰‹åŠ¨åˆ›å»ºä¸€ä¸ªLinearç‰ˆæœ¬çš„æ˜ å°„å±‚æ¥å¯¹æ¯”
    num_trend_seeds = model_mlp.trend_seed_embeddings.shape[0]
    num_detail_seeds = model_mlp.detail_seed_embeddings.shape[0]
    
    linear_trend = nn.Linear(num_trend_seeds, model_mlp.num_trend_tokens)
    linear_detail = nn.Linear(num_detail_seeds, model_mlp.num_detail_tokens)
    
    # è·å–ç›¸åŒçš„è¾“å…¥
    trend_input = model_mlp.trend_seed_embeddings.permute(1, 0)
    detail_input = model_mlp.detail_seed_embeddings.permute(1, 0)
    
    print(f"\nè¾“å…¥å½¢çŠ¶: {trend_input.shape}, {detail_input.shape}")
    
    # å‰å‘ä¼ æ’­å¯¹æ¯”
    with torch.no_grad():
        # MLPç‰ˆæœ¬
        mlp_trend_out = model_mlp.trend_mapping(trend_input)
        mlp_detail_out = model_mlp.detail_mapping(detail_input)
        
        # Linearç‰ˆæœ¬
        linear_trend_out = linear_trend(trend_input)
        linear_detail_out = linear_detail(detail_input)
    
    print(f"\nè¾“å‡ºå½¢çŠ¶å¯¹æ¯”:")
    print(f"  - MLP trend: {mlp_trend_out.shape}")
    print(f"  - Linear trend: {linear_trend_out.shape}")
    print(f"  - MLP detail: {mlp_detail_out.shape}")
    print(f"  - Linear detail: {linear_detail_out.shape}")
    
    # ç»Ÿè®¡ä¿¡æ¯å¯¹æ¯”
    print(f"\nè¾“å‡ºç»Ÿè®¡ä¿¡æ¯å¯¹æ¯”:")
    print(f"  - MLP trend - å‡å€¼: {mlp_trend_out.mean().item():.6f}, æ ‡å‡†å·®: {mlp_trend_out.std().item():.6f}")
    print(f"  - Linear trend - å‡å€¼: {linear_trend_out.mean().item():.6f}, æ ‡å‡†å·®: {linear_trend_out.std().item():.6f}")
    print(f"  - MLP detail - å‡å€¼: {mlp_detail_out.mean().item():.6f}, æ ‡å‡†å·®: {mlp_detail_out.std().item():.6f}")
    print(f"  - Linear detail - å‡å€¼: {linear_detail_out.mean().item():.6f}, æ ‡å‡†å·®: {linear_detail_out.std().item():.6f}")
    
    # MLPåº”è¯¥æœ‰ä¸åŒçš„è¾“å‡ºï¼ˆå› ä¸ºéçº¿æ€§ï¼‰
    if torch.allclose(mlp_trend_out, linear_trend_out, atol=1e-5):
        print("âš ï¸  è­¦å‘Š: MLPå’ŒLinearè¾“å‡ºè¿‡äºæ¥è¿‘ï¼Œå¯èƒ½éçº¿æ€§æ¿€æ´»æ²¡æœ‰ç”Ÿæ•ˆ")
    else:
        print("âœ… MLPå’ŒLinearè¾“å‡ºä¸åŒï¼ˆéçº¿æ€§æ¿€æ´»ç”Ÿæ•ˆï¼‰")
    
    return True


def test_end_to_end():
    """æµ‹è¯•7: ç«¯åˆ°ç«¯æµ‹è¯•"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•7: ç«¯åˆ°ç«¯æµ‹è¯•")
    print("=" * 70)
    
    configs = TestConfig()
    model = Model(configs)
    model.eval()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    batch_size = 2
    x_enc = torch.randn(batch_size, configs.seq_len, configs.enc_in)
    x_mark_enc = torch.zeros(batch_size, configs.seq_len, 4)
    x_dec = torch.randn(batch_size, configs.pred_len, configs.enc_in)
    x_mark_dec = torch.zeros(batch_size, configs.pred_len, 4)
    
    print(f"\nè¾“å…¥å½¢çŠ¶:")
    print(f"  - x_enc: {x_enc.shape}")
    print(f"  - x_mark_enc: {x_mark_enc.shape}")
    print(f"  - x_dec: {x_dec.shape}")
    print(f"  - x_mark_dec: {x_mark_dec.shape}")
    
    # å‰å‘ä¼ æ’­
    try:
        with torch.no_grad():
            output = model(x_enc, x_mark_enc, x_dec, x_mark_dec)
        
        print(f"\nè¾“å‡ºå½¢çŠ¶: {output.shape}")
        print(f"é¢„æœŸå½¢çŠ¶: ({batch_size}, {configs.pred_len}, {configs.enc_in})")
        
        if output.shape != (batch_size, configs.pred_len, configs.enc_in):
            print(f"âŒ è¾“å‡ºå½¢çŠ¶ä¸åŒ¹é…")
            return False
        print("âœ… è¾“å‡ºå½¢çŠ¶æ­£ç¡®")
        
        # æ£€æŸ¥è¾“å‡ºå€¼
        if torch.isnan(output).any():
            print("âŒ è¾“å‡ºåŒ…å«NaNå€¼")
            return False
        print("âœ… è¾“å‡ºå€¼åˆç†ï¼ˆæ— NaNï¼‰")
        
        if torch.isinf(output).any():
            print("âŒ è¾“å‡ºåŒ…å«Infå€¼")
            return False
        print("âœ… è¾“å‡ºå€¼åˆç†ï¼ˆæ— Infï¼‰")
        
    except Exception as e:
        print(f"âŒ ç«¯åˆ°ç«¯æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False
    
    return True


def run_all_tests():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("=" * 70)
    print("MLPæ˜ å°„å±‚å®Œæ•´æµ‹è¯•å¥—ä»¶")
    print("=" * 70)
    
    tests = [
        ("MLPæ˜ å°„å±‚åˆå§‹åŒ–", test_mlp_mapping_initialization),
        ("MLPæ˜ å°„å±‚ç»´åº¦æ£€æŸ¥", test_mlp_mapping_dimensions),
        ("MLPæ˜ å°„å±‚å‰å‘ä¼ æ’­", test_mlp_mapping_forward),
        ("MLPæ˜ å°„å±‚å‚æ•°é‡", test_mlp_mapping_parameters),
        ("MLPæ˜ å°„å±‚æ¢¯åº¦æµ", test_mlp_mapping_gradients),
        ("MLP vs Linearå¯¹æ¯”", test_mlp_vs_linear_comparison),
        ("ç«¯åˆ°ç«¯æµ‹è¯•", test_end_to_end),
    ]
    
    results = []
    for test_name, test_func in tests:
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"\nâŒ {test_name} æµ‹è¯•å¼‚å¸¸: {e}")
            import traceback
            traceback.print_exc()
            results.append((test_name, False))
    
    # æ±‡æ€»ç»“æœ
    print("\n" + "=" * 70)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 70)
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ… é€šè¿‡" if result else "âŒ å¤±è´¥"
        print(f"{status}: {test_name}")
    
    print(f"\næ€»è®¡: {passed}/{total} æµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
        return True
    else:
        print(f"\nâš ï¸  æœ‰ {total - passed} ä¸ªæµ‹è¯•å¤±è´¥")
        return False


if __name__ == '__main__':
    success = run_all_tests()
    sys.exit(0 if success else 1)


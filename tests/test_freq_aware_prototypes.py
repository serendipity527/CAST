"""
æµ‹è¯•é¢‘ç‡æ„ŸçŸ¥åŸå‹å¢å¼ºï¼ˆFrequency-Aware Prototype Enhancementï¼‰åŠŸèƒ½

æ ¸å¿ƒæ€æƒ³ï¼šP_trend = P_shared + B_trend, P_detail = P_shared + B_detail
"""

import torch
import torch.nn as nn
import sys
import os

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from models.TimeLLM import Model


class MockConfig:
    """æ¨¡æ‹Ÿé…ç½®ç±»"""
    def __init__(self):
        self.task_name = 'long_term_forecast'
        self.pred_len = 96
        self.seq_len = 336
        self.d_model = 512
        self.d_ff = 512
        self.llm_dim = 768
        self.patch_len = 16
        self.stride = 8
        self.enc_in = 7
        self.dropout = 0.1
        self.n_heads = 8
        self.llm_model = 'GPT2'
        self.llm_layers = 2
        self.prompt_domain = False
        self.content = 'Test dataset'
        
        # åˆ†ç¦»åŸå‹é…ç½®
        self.use_dual_prototypes = True
        self.dual_proto_trend_tokens = 1000
        self.dual_proto_detail_tokens = 1000
        
        # é¢‘ç‡æ„ŸçŸ¥åŸå‹å¢å¼ºé…ç½®
        self.use_freq_aware_prototypes = True
        self.shared_proto_size = 800
        
        # å…¶ä»–é…ç½®
        self.wavelet_mode = 'none'
        self.use_cwpr = False
        self.use_full_vocab_split = False
        self.use_semantic_filtered_mapping = False
        self.dual_proto_fusion_method = 'mean'


def test_freq_aware_prototypes_basic():
    """æµ‹è¯•1: åŸºæœ¬åŠŸèƒ½ - é¢‘ç‡æ„ŸçŸ¥åŸå‹å¢å¼ºçš„åˆå§‹åŒ–å’Œå‰å‘ä¼ æ’­"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•1: åŸºæœ¬åŠŸèƒ½ - é¢‘ç‡æ„ŸçŸ¥åŸå‹å¢å¼º")
    print("=" * 70)
    
    config = MockConfig()
    config.use_freq_aware_prototypes = True
    config.shared_proto_size = 800
    
    model = Model(config)
    
    # æ£€æŸ¥æ˜¯å¦åˆ›å»ºäº†å…±äº«æ˜ å°„å±‚å’Œåç½®
    assert model.shared_mapping is not None, "å…±äº«æ˜ å°„å±‚åº”è¯¥è¢«åˆ›å»º"
    assert model.trend_bias is not None, "è¶‹åŠ¿åç½®åº”è¯¥è¢«åˆ›å»º"
    assert model.detail_bias is not None, "ç»†èŠ‚åç½®åº”è¯¥è¢«åˆ›å»º"
    assert model.trend_mapping is None, "è¶‹åŠ¿æ˜ å°„å±‚åº”è¯¥ä¸ºNoneï¼ˆä½¿ç”¨é¢‘ç‡æ„ŸçŸ¥æ¨¡å¼ï¼‰"
    assert model.detail_mapping is None, "ç»†èŠ‚æ˜ å°„å±‚åº”è¯¥ä¸ºNoneï¼ˆä½¿ç”¨é¢‘ç‡æ„ŸçŸ¥æ¨¡å¼ï¼‰"
    
    print("âœ… åˆå§‹åŒ–æ£€æŸ¥é€šè¿‡")
    
    # æ£€æŸ¥å…±äº«åŸå‹åº“å¤§å°
    assert model.shared_proto_size == 800, f"å…±äº«åŸå‹åº“å¤§å°åº”è¯¥æ˜¯800ï¼Œå®é™…æ˜¯{model.shared_proto_size}"
    print(f"âœ… å…±äº«åŸå‹åº“å¤§å°: {model.shared_proto_size}")
    
    # æ£€æŸ¥åç½®å½¢çŠ¶
    assert model.trend_bias.shape == (800, 768), f"è¶‹åŠ¿åç½®å½¢çŠ¶åº”è¯¥æ˜¯(800, 768)ï¼Œå®é™…æ˜¯{model.trend_bias.shape}"
    assert model.detail_bias.shape == (800, 768), f"ç»†èŠ‚åç½®å½¢çŠ¶åº”è¯¥æ˜¯(800, 768)ï¼Œå®é™…æ˜¯{model.detail_bias.shape}"
    print(f"âœ… åç½®å½¢çŠ¶æ­£ç¡®: trend_bias={model.trend_bias.shape}, detail_bias={model.detail_bias.shape}")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    batch_size = 2
    seq_len = 336
    n_vars = 7
    x_enc = torch.randn(batch_size, seq_len, n_vars)
    x_mark_enc = None
    x_dec = None
    x_mark_dec = None
    
    try:
        output = model(x_enc, x_mark_enc, x_dec, x_mark_dec)
        assert output.shape == (batch_size, config.pred_len, n_vars), \
            f"è¾“å‡ºå½¢çŠ¶åº”è¯¥æ˜¯({batch_size}, {config.pred_len}, {n_vars})ï¼Œå®é™…æ˜¯{output.shape}"
        print(f"âœ… å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
    except Exception as e:
        print(f"âŒ å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        raise
    
    print("=" * 70)
    print("âœ… æµ‹è¯•1é€šè¿‡ï¼šåŸºæœ¬åŠŸèƒ½æ­£å¸¸")
    print("=" * 70)


def test_freq_aware_prototypes_prototype_generation():
    """æµ‹è¯•2: åŸå‹ç”Ÿæˆé€»è¾‘ - éªŒè¯ P_trend = P_shared + B_trend"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•2: åŸå‹ç”Ÿæˆé€»è¾‘éªŒè¯")
    print("=" * 70)
    
    config = MockConfig()
    config.use_freq_aware_prototypes = True
    config.shared_proto_size = 800
    config.dual_proto_trend_tokens = 1000
    config.dual_proto_detail_tokens = 1000
    
    model = Model(config)
    model.eval()
    
    # æ‰‹åŠ¨ç”Ÿæˆå…±äº«åŸå‹åº“
    with torch.no_grad():
        P_shared = model.shared_mapping(model.word_embeddings.permute(1, 0)).permute(1, 0)
        assert P_shared.shape == (800, 768), f"å…±äº«åŸå‹åº“å½¢çŠ¶åº”è¯¥æ˜¯(800, 768)ï¼Œå®é™…æ˜¯{P_shared.shape}"
        print(f"âœ… å…±äº«åŸå‹åº“å½¢çŠ¶: {P_shared.shape}")
        
        # åº”ç”¨åç½®
        P_trend = P_shared + model.trend_bias
        P_detail = P_shared + model.detail_bias
        
        assert P_trend.shape == (800, 768), f"è¶‹åŠ¿åŸå‹å½¢çŠ¶åº”è¯¥æ˜¯(800, 768)ï¼Œå®é™…æ˜¯{P_trend.shape}"
        assert P_detail.shape == (800, 768), f"ç»†èŠ‚åŸå‹å½¢çŠ¶åº”è¯¥æ˜¯(800, 768)ï¼Œå®é™…æ˜¯{P_detail.shape}"
        print(f"âœ… åº”ç”¨åç½®åå½¢çŠ¶: P_trend={P_trend.shape}, P_detail={P_detail.shape}")
        
        # éªŒè¯ P_trend = P_shared + B_trend
        diff_trend = torch.abs(P_trend - (P_shared + model.trend_bias)).max()
        diff_detail = torch.abs(P_detail - (P_shared + model.detail_bias)).max()
        
        assert diff_trend < 1e-6, f"P_trendåº”è¯¥ç­‰äºP_shared+B_trendï¼Œæœ€å¤§å·®å¼‚: {diff_trend}"
        assert diff_detail < 1e-6, f"P_detailåº”è¯¥ç­‰äºP_shared+B_detailï¼Œæœ€å¤§å·®å¼‚: {diff_detail}"
        print(f"âœ… åŸå‹ç”Ÿæˆå…¬å¼éªŒè¯é€šè¿‡: diff_trend={diff_trend:.2e}, diff_detail={diff_detail:.2e}")
        
        # éªŒè¯åç½®ç¡®å®æ”¹å˜äº†åŸå‹ï¼ˆåç½®ä¸åº”è¯¥å…¨ä¸º0ï¼‰
        bias_trend_norm = torch.norm(model.trend_bias).item()
        bias_detail_norm = torch.norm(model.detail_bias).item()
        assert bias_trend_norm > 0, "è¶‹åŠ¿åç½®ä¸åº”è¯¥å…¨ä¸º0"
        assert bias_detail_norm > 0, "ç»†èŠ‚åç½®ä¸åº”è¯¥å…¨ä¸º0"
        print(f"âœ… åç½®éé›¶éªŒè¯: ||B_trend||={bias_trend_norm:.4f}, ||B_detail||={bias_detail_norm:.4f}")
        
        # éªŒè¯è¶‹åŠ¿å’Œç»†èŠ‚åŸå‹ä¸åŒï¼ˆå› ä¸ºåç½®ä¸åŒï¼‰
        diff_prototypes = torch.norm(P_trend - P_detail).item()
        assert diff_prototypes > 0, "è¶‹åŠ¿å’Œç»†èŠ‚åŸå‹åº”è¯¥ä¸åŒï¼ˆå› ä¸ºåç½®ä¸åŒï¼‰"
        print(f"âœ… è¶‹åŠ¿å’Œç»†èŠ‚åŸå‹ä¸åŒ: ||P_trend - P_detail||={diff_prototypes:.4f}")
    
    print("=" * 70)
    print("âœ… æµ‹è¯•2é€šè¿‡ï¼šåŸå‹ç”Ÿæˆé€»è¾‘æ­£ç¡®")
    print("=" * 70)


def test_freq_aware_prototypes_with_projection():
    """æµ‹è¯•3: åŸå‹æŠ•å½± - å½“ shared_proto_size != num_trend_tokens æ—¶"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•3: åŸå‹æŠ•å½±åŠŸèƒ½")
    print("=" * 70)
    
    config = MockConfig()
    config.use_freq_aware_prototypes = True
    config.shared_proto_size = 800
    config.dual_proto_trend_tokens = 1000  # ä¸å…±äº«åŸå‹åº“å¤§å°ä¸åŒ
    config.dual_proto_detail_tokens = 1000
    
    model = Model(config)
    model.eval()
    
    # æ£€æŸ¥æ˜¯å¦åˆ›å»ºäº†æŠ•å½±å±‚
    assert model.proto_projection_trend is not None, "åº”è¯¥åˆ›å»ºè¶‹åŠ¿æŠ•å½±å±‚ï¼ˆå› ä¸ºå¤§å°ä¸åŒï¼‰"
    assert model.proto_projection_detail is not None, "åº”è¯¥åˆ›å»ºç»†èŠ‚æŠ•å½±å±‚ï¼ˆå› ä¸ºå¤§å°ä¸åŒï¼‰"
    print("âœ… æŠ•å½±å±‚å·²åˆ›å»º")
    
    # æ‰‹åŠ¨ç”ŸæˆåŸå‹å¹¶éªŒè¯æŠ•å½±
    with torch.no_grad():
        P_shared = model.shared_mapping(model.word_embeddings.permute(1, 0)).permute(1, 0)
        P_trend = P_shared + model.trend_bias
        P_detail = P_shared + model.detail_bias
        
        # åº”ç”¨æŠ•å½±ï¼ˆéœ€è¦å…ˆè½¬ç½®ï¼Œä¸æ¨¡å‹å®ç°ä¸€è‡´ï¼‰
        # è¾“å…¥: (shared_proto_size, d_llm) -> è½¬ç½® -> (d_llm, shared_proto_size)
        # Linear(shared_proto_size -> num_trend_tokens) -> (d_llm, num_trend_tokens) -> è½¬ç½®å› (num_trend_tokens, d_llm)
        P_trend_proj = model.proto_projection_trend(P_trend.permute(1, 0)).permute(1, 0)
        P_detail_proj = model.proto_projection_detail(P_detail.permute(1, 0)).permute(1, 0)
        
        assert P_trend_proj.shape == (1000, 768), f"æŠ•å½±åè¶‹åŠ¿åŸå‹å½¢çŠ¶åº”è¯¥æ˜¯(1000, 768)ï¼Œå®é™…æ˜¯{P_trend_proj.shape}"
        assert P_detail_proj.shape == (1000, 768), f"æŠ•å½±åç»†èŠ‚åŸå‹å½¢çŠ¶åº”è¯¥æ˜¯(1000, 768)ï¼Œå®é™…æ˜¯{P_detail_proj.shape}"
        print(f"âœ… æŠ•å½±åå½¢çŠ¶: P_trend_proj={P_trend_proj.shape}, P_detail_proj={P_detail_proj.shape}")
    
    print("=" * 70)
    print("âœ… æµ‹è¯•3é€šè¿‡ï¼šåŸå‹æŠ•å½±åŠŸèƒ½æ­£å¸¸")
    print("=" * 70)


def test_freq_aware_prototypes_backward_compatibility():
    """æµ‹è¯•4: å‘åå…¼å®¹æ€§ - ä¸å¯ç”¨é¢‘ç‡æ„ŸçŸ¥åŸå‹å¢å¼ºæ—¶åº”è¯¥ä½¿ç”¨åŸç‰ˆé€»è¾‘"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•4: å‘åå…¼å®¹æ€§éªŒè¯")
    print("=" * 70)
    
    config = MockConfig()
    config.use_freq_aware_prototypes = False  # ä¸å¯ç”¨é¢‘ç‡æ„ŸçŸ¥åŸå‹å¢å¼º
    
    model = Model(config)
    
    # æ£€æŸ¥åº”è¯¥ä½¿ç”¨åŸç‰ˆæ˜ å°„å±‚
    assert model.shared_mapping is None, "ä¸å¯ç”¨é¢‘ç‡æ„ŸçŸ¥æ—¶ï¼Œå…±äº«æ˜ å°„å±‚åº”è¯¥ä¸ºNone"
    assert model.trend_bias is None, "ä¸å¯ç”¨é¢‘ç‡æ„ŸçŸ¥æ—¶ï¼Œè¶‹åŠ¿åç½®åº”è¯¥ä¸ºNone"
    assert model.detail_bias is None, "ä¸å¯ç”¨é¢‘ç‡æ„ŸçŸ¥æ—¶ï¼Œç»†èŠ‚åç½®åº”è¯¥ä¸ºNone"
    assert model.trend_mapping is not None, "åº”è¯¥ä½¿ç”¨åŸç‰ˆè¶‹åŠ¿æ˜ å°„å±‚"
    assert model.detail_mapping is not None, "åº”è¯¥ä½¿ç”¨åŸç‰ˆç»†èŠ‚æ˜ å°„å±‚"
    
    print("âœ… å‘åå…¼å®¹æ€§æ£€æŸ¥é€šè¿‡ï¼šä½¿ç”¨åŸç‰ˆæ˜ å°„å±‚")
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    batch_size = 2
    seq_len = 336
    n_vars = 7
    x_enc = torch.randn(batch_size, seq_len, n_vars)
    x_mark_enc = None
    x_dec = None
    x_mark_dec = None
    
    try:
        output = model(x_enc, x_mark_enc, x_dec, x_mark_dec)
        assert output.shape == (batch_size, config.pred_len, n_vars)
        print(f"âœ… åŸç‰ˆæ¨¡å¼å‰å‘ä¼ æ’­æˆåŠŸï¼Œè¾“å‡ºå½¢çŠ¶: {output.shape}")
    except Exception as e:
        print(f"âŒ åŸç‰ˆæ¨¡å¼å‰å‘ä¼ æ’­å¤±è´¥: {e}")
        raise
    
    print("=" * 70)
    print("âœ… æµ‹è¯•4é€šè¿‡ï¼šå‘åå…¼å®¹æ€§æ­£å¸¸")
    print("=" * 70)


def test_freq_aware_prototypes_gradient_flow():
    """æµ‹è¯•5: æ¢¯åº¦æµéªŒè¯ - ç¡®ä¿åç½®å‚æ•°å¯ä»¥æ›´æ–°"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•5: æ¢¯åº¦æµéªŒè¯")
    print("=" * 70)
    
    config = MockConfig()
    config.use_freq_aware_prototypes = True
    config.shared_proto_size = 800
    
    model = Model(config)
    model.train()
    
    # æ£€æŸ¥å‚æ•°æ˜¯å¦å¯è®­ç»ƒ
    assert model.trend_bias.requires_grad, "è¶‹åŠ¿åç½®åº”è¯¥å¯è®­ç»ƒ"
    assert model.detail_bias.requires_grad, "ç»†èŠ‚åç½®åº”è¯¥å¯è®­ç»ƒ"
    
    # shared_mapping å¯èƒ½æ˜¯ nn.Linear æˆ– nn.Sequentialï¼Œéœ€è¦åˆ†åˆ«å¤„ç†
    if isinstance(model.shared_mapping, nn.Linear):
        assert model.shared_mapping.weight.requires_grad, "å…±äº«æ˜ å°„å±‚åº”è¯¥å¯è®­ç»ƒ"
    elif isinstance(model.shared_mapping, nn.Sequential):
        assert model.shared_mapping[0].weight.requires_grad, "å…±äº«æ˜ å°„å±‚åº”è¯¥å¯è®­ç»ƒ"
    else:
        # æ£€æŸ¥æ˜¯å¦æœ‰å¯è®­ç»ƒå‚æ•°
        has_trainable = any(p.requires_grad for p in model.shared_mapping.parameters())
        assert has_trainable, "å…±äº«æ˜ å°„å±‚åº”è¯¥æœ‰å¯è®­ç»ƒå‚æ•°"
    print("âœ… å‚æ•°å¯è®­ç»ƒæ€§æ£€æŸ¥é€šè¿‡")
    
    # åˆ›å»ºä¼˜åŒ–å™¨
    optimizer = torch.optim.Adam([
        {'params': model.trend_bias},
        {'params': model.detail_bias},
        {'params': model.shared_mapping.parameters()}
    ], lr=0.001)
    
    # è®°å½•åˆå§‹å€¼
    trend_bias_init = model.trend_bias.data.clone()
    detail_bias_init = model.detail_bias.data.clone()
    
    # å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­
    batch_size = 2
    seq_len = 336
    n_vars = 7
    x_enc = torch.randn(batch_size, seq_len, n_vars)
    x_mark_enc = None
    x_dec = None
    x_mark_dec = None
    
    output = model(x_enc, x_mark_enc, x_dec, x_mark_dec)
    loss = output.mean()
    loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦æ˜¯å¦å­˜åœ¨
    assert model.trend_bias.grad is not None, "è¶‹åŠ¿åç½®åº”è¯¥æœ‰æ¢¯åº¦"
    assert model.detail_bias.grad is not None, "ç»†èŠ‚åç½®åº”è¯¥æœ‰æ¢¯åº¦"
    print("âœ… æ¢¯åº¦å­˜åœ¨æ€§æ£€æŸ¥é€šè¿‡")
    
    # æ›´æ–°å‚æ•°
    optimizer.step()
    
    # æ£€æŸ¥å‚æ•°æ˜¯å¦æ›´æ–°
    trend_bias_updated = model.trend_bias.data.clone()
    detail_bias_updated = model.detail_bias.data.clone()
    
    diff_trend = torch.norm(trend_bias_init - trend_bias_updated).item()
    diff_detail = torch.norm(detail_bias_init - detail_bias_updated).item()
    
    assert diff_trend > 0, "è¶‹åŠ¿åç½®åº”è¯¥è¢«æ›´æ–°"
    assert diff_detail > 0, "ç»†èŠ‚åç½®åº”è¯¥è¢«æ›´æ–°"
    print(f"âœ… å‚æ•°æ›´æ–°éªŒè¯: ||Î”B_trend||={diff_trend:.6f}, ||Î”B_detail||={diff_detail:.6f}")
    
    print("=" * 70)
    print("âœ… æµ‹è¯•5é€šè¿‡ï¼šæ¢¯åº¦æµæ­£å¸¸")
    print("=" * 70)


def test_freq_aware_prototypes_different_modes():
    """æµ‹è¯•6: ä¸åŒæ¨¡å¼ä¸‹çš„é¢‘ç‡æ„ŸçŸ¥åŸå‹å¢å¼º"""
    print("\n" + "=" * 70)
    print("æµ‹è¯•6: ä¸åŒæ¨¡å¼ä¸‹çš„é¢‘ç‡æ„ŸçŸ¥åŸå‹å¢å¼º")
    print("=" * 70)
    
    # æµ‹è¯•åŸç‰ˆæ˜ å°„æ¨¡å¼
    print("\n[6.1] æµ‹è¯•åŸç‰ˆæ˜ å°„æ¨¡å¼...")
    config1 = MockConfig()
    config1.use_freq_aware_prototypes = True
    config1.use_full_vocab_split = False
    config1.use_semantic_filtered_mapping = False
    
    model1 = Model(config1)
    assert model1.shared_mapping is not None, "åŸç‰ˆæ˜ å°„æ¨¡å¼åº”è¯¥åˆ›å»ºå…±äº«æ˜ å°„å±‚"
    assert isinstance(model1.shared_mapping, nn.Linear), "åŸç‰ˆæ˜ å°„æ¨¡å¼åº”è¯¥ä½¿ç”¨Linearå±‚"
    print("âœ… åŸç‰ˆæ˜ å°„æ¨¡å¼æ£€æŸ¥é€šè¿‡")
    
    # æµ‹è¯•å…¨è¯è¡¨åˆ‡åˆ†æ¨¡å¼ï¼ˆéœ€è¦å®é™…è¿è¡Œæ‰èƒ½æµ‹è¯•ï¼Œè¿™é‡Œåªæ£€æŸ¥é…ç½®ï¼‰
    print("\n[6.2] æµ‹è¯•å…¨è¯è¡¨åˆ‡åˆ†æ¨¡å¼é…ç½®...")
    config2 = MockConfig()
    config2.use_freq_aware_prototypes = True
    config2.use_full_vocab_split = True
    config2.use_semantic_filtered_mapping = False
    
    # æ³¨æ„ï¼šå…¨è¯è¡¨åˆ‡åˆ†éœ€è¦å®é™…çš„vocab_splitterï¼Œè¿™é‡Œåªæ£€æŸ¥é…ç½®é€»è¾‘
    print("âœ… å…¨è¯è¡¨åˆ‡åˆ†æ¨¡å¼é…ç½®æ£€æŸ¥é€šè¿‡ï¼ˆéœ€è¦å®é™…æ•°æ®æ‰èƒ½å®Œæ•´æµ‹è¯•ï¼‰")
    
    print("=" * 70)
    print("âœ… æµ‹è¯•6é€šè¿‡ï¼šä¸åŒæ¨¡å¼é…ç½®æ­£ç¡®")
    print("=" * 70)


if __name__ == '__main__':
    print("\n" + "=" * 70)
    print("å¼€å§‹æµ‹è¯•é¢‘ç‡æ„ŸçŸ¥åŸå‹å¢å¼ºåŠŸèƒ½")
    print("=" * 70)
    
    try:
        test_freq_aware_prototypes_basic()
        test_freq_aware_prototypes_prototype_generation()
        test_freq_aware_prototypes_with_projection()
        test_freq_aware_prototypes_backward_compatibility()
        test_freq_aware_prototypes_gradient_flow()
        test_freq_aware_prototypes_different_modes()
        
        print("\n" + "=" * 70)
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼é¢‘ç‡æ„ŸçŸ¥åŸå‹å¢å¼ºåŠŸèƒ½å®ç°æ­£ç¡®")
        print("=" * 70)
    except Exception as e:
        print("\n" + "=" * 70)
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        print("=" * 70)
        import traceback
        traceback.print_exc()
        sys.exit(1)


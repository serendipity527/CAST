#!/usr/bin/env python3
"""
æµ‹è¯•å°æ³¢PromptåŠŸèƒ½çš„å‘½ä»¤è¡Œå‚æ•°æ§åˆ¶
éªŒè¯ä¸åŒå‚æ•°ç»„åˆä¸‹çš„è¡Œä¸º
"""

import torch
import numpy as np
import subprocess
import os
import sys

def create_test_script():
    """åˆ›å»ºä¸€ä¸ªç®€åŒ–çš„æµ‹è¯•è„šæœ¬æ¥éªŒè¯å‚æ•°ä¼ é€’"""
    test_script_content = '''
import argparse
import torch
import numpy as np
from models.TimeLLM import Model

def create_test_config(args_dict):
    """æ ¹æ®å‚æ•°å­—å…¸åˆ›å»ºé…ç½®å¯¹è±¡"""
    class TestConfig:
        def __init__(self, **kwargs):
            # åŸºæœ¬é…ç½®
            self.task_name = 'long_term_forecast'
            self.pred_len = 24
            self.seq_len = 96
            self.d_ff = 32
            self.llm_dim = 768
            self.patch_len = 16
            self.stride = 8
            self.enc_in = 1
            self.dropout = 0.1
            self.d_model = 16
            self.n_heads = 8
            self.llm_layers = 2
            self.llm_model = 'GPT2'
            self.prompt_domain = 0
            
            # å°æ³¢é…ç½®
            self.wavelet_mode = 'none'
            self.use_haar_wavelet = 0
            self.use_dual_scale_head = 0
            self.use_freq_decoupled_head = 0
            
            # ä»å‚æ•°å­—å…¸æ›´æ–°é…ç½®
            for key, value in kwargs.items():
                setattr(self, key, value)
    
    return TestConfig(**args_dict)

def test_wavelet_prompt_params():
    """æµ‹è¯•ä¸åŒçš„å°æ³¢promptå‚æ•°ç»„åˆ"""
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®
    T = 96
    t = torch.linspace(0, 4*np.pi, T)
    
    # æµ‹è¯•ä¿¡å·ï¼šæ··åˆä¿¡å·ï¼ˆä¸­ç­‰æ³¢åŠ¨ï¼‰
    test_signal = torch.sin(t) + 0.3 * torch.sin(5 * t) + 0.1 * torch.randn(T)
    x_test = test_signal.unsqueeze(0).unsqueeze(-1)  # (1, T, 1)
    
    print("ğŸ§ª å°æ³¢Promptå‚æ•°æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•é…ç½®åˆ—è¡¨
    test_configs = [
        {
            'name': 'å…³é—­å°æ³¢Prompt',
            'params': {
                'use_wavelet_prompt': 0
            }
        },
        {
            'name': 'å¯ç”¨Haarå°æ³¢Prompt',
            'params': {
                'use_wavelet_prompt': 1,
                'wavelet_prompt_method': 'haar',
                'prompt_hfer_threshold': 0.15
            }
        },
        {
            'name': 'å¯ç”¨ç®€åŒ–é¢‘åŸŸåˆ†æ',
            'params': {
                'use_wavelet_prompt': 1,
                'wavelet_prompt_method': 'simple',
                'prompt_hfer_threshold': 0.15
            }
        },
        {
            'name': 'è°ƒæ•´HFERé˜ˆå€¼ï¼ˆæ•æ„Ÿï¼‰',
            'params': {
                'use_wavelet_prompt': 1,
                'wavelet_prompt_method': 'haar',
                'prompt_hfer_threshold': 0.05  # æ›´æ•æ„Ÿçš„é˜ˆå€¼
            }
        },
        {
            'name': 'è°ƒæ•´HFERé˜ˆå€¼ï¼ˆä¸æ•æ„Ÿï¼‰',
            'params': {
                'use_wavelet_prompt': 1,
                'wavelet_prompt_method': 'haar',
                'prompt_hfer_threshold': 0.30  # ä¸å¤ªæ•æ„Ÿçš„é˜ˆå€¼
            }
        }
    ]
    
    for i, test_config in enumerate(test_configs):
        print(f"\\nğŸ“‹ æµ‹è¯• {i+1}: {test_config['name']}")
        print("-" * 40)
        
        try:
            # åˆ›å»ºé…ç½®
            config = create_test_config(test_config['params'])
            
            # åˆ›å»ºæ¨¡å‹
            model = Model(config)
            
            # æµ‹è¯•å°æ³¢ç‰¹å¾åˆ†æï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if config.use_wavelet_prompt:
                hfer, volatility, smoothness_level = model.analyze_wavelet_features(test_signal)
                wavelet_desc = model.get_wavelet_description(hfer, volatility, smoothness_level)
                
                print(f"  âœ… å°æ³¢ç‰¹å¾åˆ†ææˆåŠŸ")
                print(f"     - æ–¹æ³•: {config.wavelet_prompt_method}")
                print(f"     - HFERé˜ˆå€¼: {config.prompt_hfer_threshold}")
                print(f"     - é«˜é¢‘èƒ½é‡å æ¯”: {hfer:.3f}")
                print(f"     - æ³¢åŠ¨æ€§: {volatility:.3f}")
                print(f"     - å¹³æ»‘åº¦ç­‰çº§: {smoothness_level}/4")
                print(f"     - æè¿°: {wavelet_desc}")
            else:
                print(f"  âœ… å°æ³¢Promptå·²å…³é—­ï¼Œä½¿ç”¨åŸç‰ˆPrompt")
            
        except Exception as e:
            print(f"  âŒ æµ‹è¯•å¤±è´¥: {str(e)}")
    
    print(f"\\n" + "=" * 60)
    print("ğŸ‰ å‚æ•°æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_wavelet_prompt_params()
'''
    
    # å†™å…¥æµ‹è¯•è„šæœ¬
    with open('/home/dmx_MT/LZF/project/CAST/temp_test_params.py', 'w', encoding='utf-8') as f:
        f.write(test_script_content)

def test_cli_parameters():
    """æµ‹è¯•å‘½ä»¤è¡Œå‚æ•°çš„ä¼ é€’å’Œè§£æ"""
    print("ğŸ”§ å‘½ä»¤è¡Œå‚æ•°æ§åˆ¶æµ‹è¯•")
    print("=" * 70)
    
    # åˆ›å»ºæµ‹è¯•è„šæœ¬
    create_test_script()
    
    print("âœ… æµ‹è¯•è„šæœ¬å·²åˆ›å»º")
    
    # è¿è¡Œå‚æ•°æµ‹è¯•
    print("\nğŸ“Š è¿è¡Œå‚æ•°æµ‹è¯•...")
    try:
        result = subprocess.run([
            'conda', 'run', '-n', 'timellm', 
            'python', '/home/dmx_MT/LZF/project/CAST/temp_test_params.py'
        ], 
        capture_output=True, 
        text=True, 
        cwd='/home/dmx_MT/LZF/project/CAST'
        )
        
        print("STDOUT:")
        print(result.stdout)
        
        if result.stderr:
            print("STDERR:")
            print(result.stderr)
            
        if result.returncode == 0:
            print("âœ… å‚æ•°æµ‹è¯•æˆåŠŸå®Œæˆ")
        else:
            print(f"âš ï¸ æµ‹è¯•é€€å‡ºç : {result.returncode}")
            
    except Exception as e:
        print(f"âŒ è¿è¡Œæµ‹è¯•æ—¶å‡ºé”™: {str(e)}")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    try:
        os.remove('/home/dmx_MT/LZF/project/CAST/temp_test_params.py')
        print("ğŸ§¹ ä¸´æ—¶æ–‡ä»¶å·²æ¸…ç†")
    except:
        pass

def show_usage_examples():
    """å±•ç¤ºå¦‚ä½•ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°"""
    print("\n" + "=" * 70)
    print("ğŸ“– å‘½ä»¤è¡Œå‚æ•°ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 70)
    
    examples = [
        {
            'title': 'å…³é—­å°æ³¢Promptï¼ˆé»˜è®¤ï¼‰',
            'command': 'python run_main.py --use_wavelet_prompt 0 --model TimeLLM --data ETTh1 --is_training 1 --model_id test'
        },
        {
            'title': 'å¯ç”¨Haarå°æ³¢Prompt',
            'command': 'python run_main.py --use_wavelet_prompt 1 --wavelet_prompt_method haar --model TimeLLM --data ETTh1 --is_training 1 --model_id test'
        },
        {
            'title': 'ä½¿ç”¨ç®€åŒ–é¢‘åŸŸåˆ†æ',
            'command': 'python run_main.py --use_wavelet_prompt 1 --wavelet_prompt_method simple --model TimeLLM --data ETTh1 --is_training 1 --model_id test'
        },
        {
            'title': 'è°ƒæ•´HFERé˜ˆå€¼ï¼ˆæ›´æ•æ„Ÿï¼‰',
            'command': 'python run_main.py --use_wavelet_prompt 1 --prompt_hfer_threshold 0.05 --model TimeLLM --data ETTh1 --is_training 1 --model_id test'
        },
        {
            'title': 'è°ƒæ•´HFERé˜ˆå€¼ï¼ˆä¸æ•æ„Ÿï¼‰',
            'command': 'python run_main.py --use_wavelet_prompt 1 --prompt_hfer_threshold 0.30 --model TimeLLM --data ETTh1 --is_training 1 --model_id test'
        }
    ]
    
    for i, example in enumerate(examples):
        print(f"\nğŸ”¹ ç¤ºä¾‹ {i+1}: {example['title']}")
        print(f"   {example['command']}")
    
    print(f"\nğŸ“ å‚æ•°è¯´æ˜:")
    print("  --use_wavelet_prompt: 0=å…³é—­, 1=å¯ç”¨å°æ³¢Promptå¢å¼º")
    print("  --wavelet_prompt_method: haar=Haarå°æ³¢åˆ†è§£, simple=ç®€åŒ–é¢‘åŸŸåˆ†æ")
    print("  --prompt_hfer_threshold: é«˜é¢‘èƒ½é‡å æ¯”é˜ˆå€¼ï¼Œå½±å“å¹³æ»‘åº¦ç­‰çº§åˆ¤æ–­")

def create_comparison_demo():
    """åˆ›å»ºå¯¹æ¯”æ¼”ç¤ºè„šæœ¬"""
    demo_content = '''#!/usr/bin/env python3
"""
å¯¹æ¯”æ¼”ç¤ºï¼šå¯ç”¨/å…³é—­å°æ³¢Promptçš„æ•ˆæœ
"""

import argparse
import torch
import numpy as np
from models.TimeLLM import Model

def demo_prompt_comparison():
    """æ¼”ç¤ºå¯ç”¨å’Œå…³é—­å°æ³¢Promptçš„å¯¹æ¯”æ•ˆæœ"""
    
    # åˆ›å»ºæµ‹è¯•ä¿¡å·
    T = 96
    t = torch.linspace(0, 4*np.pi, T)
    noisy_signal = torch.randn(T) * 0.8 + torch.sin(t)  # é«˜å™ªå£°ä¿¡å·
    smooth_signal = torch.sin(0.5 * t) + 0.05 * t  # å¹³æ»‘ä¿¡å·
    
    signals = {
        'noisy': noisy_signal,
        'smooth': smooth_signal
    }
    
    print("ğŸ”„ å°æ³¢Promptå¼€å¯/å…³é—­å¯¹æ¯”æ¼”ç¤º")
    print("=" * 70)
    
    for signal_name, signal in signals.items():
        print(f"\\nğŸ“Š ä¿¡å·ç±»å‹: {signal_name.upper()}")
        print("-" * 50)
        
        for use_wavelet in [0, 1]:
            status = "å¼€å¯" if use_wavelet else "å…³é—­"
            print(f"\\nğŸ”§ å°æ³¢Prompt: {status}")
            
            # é…ç½®ç±»
            class DemoConfig:
                def __init__(self):
                    self.task_name = 'long_term_forecast'
                    self.pred_len = 24
                    self.seq_len = 96
                    self.d_ff = 32
                    self.llm_dim = 768
                    self.patch_len = 16
                    self.stride = 8
                    self.enc_in = 1
                    self.dropout = 0.1
                    self.d_model = 16
                    self.n_heads = 8
                    self.llm_layers = 2
                    self.llm_model = 'GPT2'
                    self.prompt_domain = 0
                    self.wavelet_mode = 'none'
                    self.use_haar_wavelet = 0
                    self.use_dual_scale_head = 0
                    self.use_freq_decoupled_head = 0
                    
                    # å°æ³¢Prompté…ç½®
                    self.use_wavelet_prompt = use_wavelet
                    self.wavelet_prompt_method = 'haar'
                    self.prompt_hfer_threshold = 0.15
            
            try:
                config = DemoConfig()
                model = Model(config)
                
                if use_wavelet:
                    hfer, volatility, smoothness_level = model.analyze_wavelet_features(signal)
                    wavelet_desc = model.get_wavelet_description(hfer, volatility, smoothness_level)
                    print(f"   å°æ³¢ç‰¹å¾: HFER={hfer:.3f}, æ³¢åŠ¨æ€§={volatility:.3f}, ç­‰çº§={smoothness_level}")
                    print(f"   æè¿°: {wavelet_desc}")
                else:
                    print(f"   ä½¿ç”¨åŸç‰ˆPromptï¼ˆæ— é¢‘åŸŸä¿¡æ¯ï¼‰")
                    
            except Exception as e:
                print(f"   âŒ é”™è¯¯: {str(e)}")

if __name__ == "__main__":
    demo_prompt_comparison()
'''
    
    with open('/home/dmx_MT/LZF/project/CAST/demo_prompt_comparison.py', 'w', encoding='utf-8') as f:
        f.write(demo_content)
    
    print("ğŸ“„ å¯¹æ¯”æ¼”ç¤ºè„šæœ¬å·²åˆ›å»º: demo_prompt_comparison.py")

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ å°æ³¢Promptå‘½ä»¤è¡Œå‚æ•°æ§åˆ¶æµ‹è¯•")
    print("=" * 70)
    
    # 1. æµ‹è¯•å‚æ•°ä¼ é€’å’Œè§£æ
    test_cli_parameters()
    
    # 2. å±•ç¤ºä½¿ç”¨ç¤ºä¾‹
    show_usage_examples()
    
    # 3. åˆ›å»ºå¯¹æ¯”æ¼”ç¤º
    create_comparison_demo()
    
    print("\n" + "=" * 70)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•å®Œæˆï¼")
    print("=" * 70)
    
    print("\nğŸ“‹ æ€»ç»“:")
    print("âœ… å·²æ·»åŠ 3ä¸ªæ–°çš„å‘½ä»¤è¡Œå‚æ•°:")
    print("   - --use_wavelet_prompt: æ§åˆ¶æ˜¯å¦å¯ç”¨å°æ³¢Promptå¢å¼º")
    print("   - --wavelet_prompt_method: é€‰æ‹©åˆ†ææ–¹æ³•ï¼ˆhaar/simpleï¼‰")
    print("   - --prompt_hfer_threshold: è°ƒæ•´æ•æ„Ÿåº¦é˜ˆå€¼")
    print("âœ… TimeLLM.pyå·²æ”¯æŒå‚æ•°æ§åˆ¶å’Œæ¡ä»¶æ‰§è¡Œ")
    print("âœ… æä¾›äº†å®Œæ•´çš„ä½¿ç”¨ç¤ºä¾‹å’Œå¯¹æ¯”æ¼”ç¤º")
    
    print("\nğŸš€ ç°åœ¨ä½ å¯ä»¥é€šè¿‡ä»¥ä¸‹æ–¹å¼å¯ç”¨å°æ³¢Prompt:")
    print("   conda run -n timellm python run_main.py \\")
    print("     --use_wavelet_prompt 1 \\")
    print("     --wavelet_prompt_method haar \\")
    print("     --model TimeLLM --data ETTh1 --is_training 1 --model_id test")

if __name__ == "__main__":
    main()

"""
é¢‘ç‡è§£è€¦è¾“å‡ºå¤´ (Frequency Decoupled Head)

å®ç°ä¸‰é¢‘å¸¦è§£è€¦å¤´ (Tri-Band Decoupled Head) V2.0 æ–¹æ¡ˆï¼š
1. ä¸‰ä¸ªç‹¬ç«‹çš„æŠ•å½±å¤´åˆ†åˆ«é¢„æµ‹ä½é¢‘/ä¸­é¢‘/é«˜é¢‘æ—¶åŸŸåˆ†é‡
2. é«˜é¢‘å¤´ä½¿ç”¨éšå±‚ SoftThreshold å»å™ª
3. æ·±åº¦ç›‘ç£ï¼šä½¿ç”¨æ ‡å‡† SWT åˆ†è§£ Ground Truth ä½œä¸ºè¾…åŠ©ç›‘ç£ç›®æ ‡
4. æ—¶åŸŸç›´æ¥ç›¸åŠ é‡æ„

æ ¸å¿ƒè®¾è®¡ï¼š
- Head 1 (Trend): Linearï¼Œæ— æ­£åˆ™ï¼Œé¢„æµ‹å¹³æ»‘è¶‹åŠ¿
- Head 2 (Mid): Linear + Dropout(0.2)ï¼Œé¢„æµ‹ä¸­é¢‘æ³¢åŠ¨
- Head 3 (Detail): Linear + SoftThreshold(éšå±‚) + Dropout(0.5)ï¼Œé¢„æµ‹é«˜é¢‘ç»†èŠ‚

Author: CAST Project
Date: 2024
"""

import torch
import torch.nn as nn
import torch.nn.functional as F
import math


class SoftThreshold(nn.Module):
    """
    å¯å­¦ä¹ è½¯é˜ˆå€¼æ¨¡å—
    
    åœ¨éšç©ºé—´ä¸­åº”ç”¨è½¯é˜ˆå€¼å»å™ªï¼Œæ»¤é™¤å°å¹…åº¦çš„å™ªå£°æ¿€æ´»ã€‚
    å…¬å¼: y = sign(x) * ReLU(|x| - Ï„)
    
    Args:
        num_features: ç‰¹å¾ç»´åº¦
        init_tau: åˆå§‹é˜ˆå€¼ (é»˜è®¤ 0.1)
    """
    def __init__(self, num_features, init_tau=0.1):
        super(SoftThreshold, self).__init__()
        self.tau = nn.Parameter(torch.ones(num_features) * init_tau)
    
    def forward(self, x):
        tau = torch.abs(self.tau)  # ç¡®ä¿é˜ˆå€¼ä¸ºæ­£
        return torch.sign(x) * F.relu(torch.abs(x) - tau)
    
    def extra_repr(self):
        return f'num_features={self.tau.shape[0]}, init_tau={self.tau.mean().item():.4f}'


class TriBandDecoupledHead(nn.Module):
    """
    ä¸‰é¢‘å¸¦è§£è€¦è¾“å‡ºå¤´ (Tri-Band Decoupled Head)
    
    å°† LLM çš„éšçŠ¶æ€è§£è€¦ä¸ºä¸‰ä¸ªé¢‘ç‡åˆ†é‡çš„æ—¶åŸŸé¢„æµ‹ï¼Œç„¶åç›¸åŠ å¾—åˆ°æœ€ç»ˆé¢„æµ‹ã€‚
    
    æ¶æ„:
        LLM Output (B*N, nf)
            â”‚
            â”œâ”€â”€â–º Head_Trend (Linear) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Pred_Trend
            â”‚
            â”œâ”€â”€â–º Head_Mid (Linear + Dropout) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–º Pred_Mid
            â”‚
            â””â”€â”€â–º Head_Detail (Linear + SoftThreshold + Dropout) â”€â”€â–º Pred_Detail
            â”‚
            â–¼
        Final = Pred_Trend + Pred_Mid + Pred_Detail
    
    Args:
        n_vars: å˜é‡æ•°é‡
        nf: è¾“å…¥ç‰¹å¾ç»´åº¦ (d_ff * patch_nums)
        target_window: é¢„æµ‹çª—å£é•¿åº¦ (pred_len)
        head_dropout: è¾“å‡º Dropout æ¯”ä¾‹
        mid_dropout: ä¸­é¢‘å¤´ Dropout æ¯”ä¾‹ (é»˜è®¤ 0.2)
        high_dropout: é«˜é¢‘å¤´ Dropout æ¯”ä¾‹ (é»˜è®¤ 0.5)
        use_soft_threshold: æ˜¯å¦åœ¨é«˜é¢‘å¤´ä½¿ç”¨è½¯é˜ˆå€¼ (é»˜è®¤ True)
        soft_threshold_init: è½¯é˜ˆå€¼åˆå§‹å€¼ (é»˜è®¤ 0.1)
        use_conv: æ˜¯å¦ä½¿ç”¨ Conv1d æ›¿ä»£ Linear (å¢åŠ ä½ç½®æ„ŸçŸ¥ï¼Œé»˜è®¤ False)
    """
    
    def __init__(self, n_vars, nf, target_window, head_dropout=0.1,
                 mid_dropout=0.2, high_dropout=0.5,
                 use_soft_threshold=True, soft_threshold_init=0.1,
                 use_conv=False):
        super(TriBandDecoupledHead, self).__init__()
        
        self.n_vars = n_vars
        self.nf = nf
        self.target_window = target_window
        self.use_soft_threshold = use_soft_threshold
        self.use_conv = use_conv
        
        # å±•å¹³å±‚
        self.flatten = nn.Flatten(start_dim=-2)
        
        # ========== Head 1: ä½é¢‘/è¶‹åŠ¿å¤´ (æ— æ­£åˆ™) ==========
        if use_conv:
            # Conv1d æä¾›ä½ç½®æ„ŸçŸ¥èƒ½åŠ›
            self.head_trend = nn.Conv1d(nf, target_window, kernel_size=1)
        else:
            self.head_trend = nn.Linear(nf, target_window)
        
        # ========== Head 2: ä¸­é¢‘å¤´ (è½»å¾® Dropout) ==========
        if use_conv:
            self.head_mid_proj = nn.Conv1d(nf, target_window, kernel_size=1)
        else:
            self.head_mid_proj = nn.Linear(nf, target_window)
        self.head_mid_dropout = nn.Dropout(mid_dropout)
        
        # ========== Head 3: é«˜é¢‘/ç»†èŠ‚å¤´ (å¼ºæ­£åˆ™) ==========
        # è®¾è®¡ï¼šå…ˆæŠ•å½±åˆ°éšå±‚ â†’ è½¯é˜ˆå€¼å»å™ª â†’ é‡æ„åˆ°æ—¶åŸŸ
        hidden_dim = max(nf // 2, target_window)  # éšå±‚ç»´åº¦
        
        if use_conv:
            self.head_detail_to_latent = nn.Conv1d(nf, hidden_dim, kernel_size=1)
            self.head_detail_to_time = nn.Conv1d(hidden_dim, target_window, kernel_size=1)
        else:
            self.head_detail_to_latent = nn.Linear(nf, hidden_dim)
            self.head_detail_to_time = nn.Linear(hidden_dim, target_window)
        
        if use_soft_threshold:
            self.soft_threshold = SoftThreshold(hidden_dim, init_tau=soft_threshold_init)
        
        self.head_detail_dropout = nn.Dropout(high_dropout)
        
        # è¾“å‡º Dropout
        self.output_dropout = nn.Dropout(head_dropout)
        
        # åˆå§‹åŒ–æƒé‡
        self._init_weights()
        
        # æ‰“å°é…ç½®
        self._print_config()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.Conv1d):
                nn.init.kaiming_normal_(m.weight, mode='fan_in', nonlinearity='leaky_relu')
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
    
    def _print_config(self):
        """æ‰“å°æ¨¡å—é…ç½®"""
        print("=" * 70)
        print("[TriBandDecoupledHead] ä¸‰é¢‘å¸¦è§£è€¦è¾“å‡ºå¤´å·²å¯ç”¨")
        print("=" * 70)
        print(f"  â”œâ”€ è¾“å…¥ç‰¹å¾ç»´åº¦: {self.nf}")
        print(f"  â”œâ”€ é¢„æµ‹çª—å£é•¿åº¦: {self.target_window}")
        print(f"  â”œâ”€ å˜é‡æ•°é‡: {self.n_vars}")
        print(f"  â”œâ”€ æŠ•å½±ç±»å‹: {'Conv1d' if self.use_conv else 'Linear'}")
        print(f"  â”œâ”€ Head 1 (Trend): æ— æ­£åˆ™åŒ–")
        print(f"  â”œâ”€ Head 2 (Mid): Dropout={self.head_mid_dropout.p}")
        print(f"  â”œâ”€ Head 3 (Detail):")
        print(f"  â”‚   â”œâ”€ SoftThreshold: {'âœ… å¯ç”¨' if self.use_soft_threshold else 'âŒ å…³é—­'}")
        print(f"  â”‚   â””â”€ Dropout={self.head_detail_dropout.p}")
        print(f"  â””â”€ è¾“å‡º Dropout: {self.output_dropout.p}")
        print("=" * 70)
    
    def forward(self, x, return_components=False):
        """
        å‰å‘ä¼ æ’­
        
        Args:
            x: LLM è¾“å‡ºï¼Œå½¢çŠ¶ (B, n_vars, d_ff, patch_nums) æˆ– (B, n_vars, nf)
            return_components: æ˜¯å¦è¿”å›ä¸‰ä¸ªé¢‘ç‡åˆ†é‡ (ç”¨äºæ·±åº¦ç›‘ç£)
        
        Returns:
            final_pred: æœ€ç»ˆé¢„æµ‹ï¼Œå½¢çŠ¶ (B, target_window, n_vars)
            components: (å¯é€‰) å­—å…¸ï¼ŒåŒ…å« pred_trend, pred_mid, pred_detail
        """
        # è¾“å…¥å½¢çŠ¶å¤„ç†
        if x.dim() == 4:
            # (B, n_vars, d_ff, patch_nums) -> (B, n_vars, nf)
            B, N, D, P = x.shape
            x = self.flatten(x)  # (B, n_vars, d_ff * patch_nums)
        else:
            B, N, _ = x.shape
        
        # ========== Head 1: ä½é¢‘è¶‹åŠ¿é¢„æµ‹ ==========
        if self.use_conv:
            pred_trend = self.head_trend(x.transpose(-1, -2)).transpose(-1, -2)
        else:
            pred_trend = self.head_trend(x)  # (B, n_vars, target_window)
        
        # ========== Head 2: ä¸­é¢‘é¢„æµ‹ ==========
        if self.use_conv:
            pred_mid = self.head_mid_proj(x.transpose(-1, -2)).transpose(-1, -2)
        else:
            pred_mid = self.head_mid_proj(x)
        pred_mid = self.head_mid_dropout(pred_mid)
        
        # ========== Head 3: é«˜é¢‘ç»†èŠ‚é¢„æµ‹ ==========
        # Step 1: æŠ•å½±åˆ°éšå±‚
        if self.use_conv:
            h_detail = self.head_detail_to_latent(x.transpose(-1, -2)).transpose(-1, -2)
        else:
            h_detail = self.head_detail_to_latent(x)
        
        # Step 2: éšå±‚è½¯é˜ˆå€¼å»å™ª
        if self.use_soft_threshold:
            h_detail = self.soft_threshold(h_detail)
        
        # Step 3: Dropout
        h_detail = self.head_detail_dropout(h_detail)
        
        # Step 4: é‡æ„åˆ°æ—¶åŸŸ
        if self.use_conv:
            pred_detail = self.head_detail_to_time(h_detail.transpose(-1, -2)).transpose(-1, -2)
        else:
            pred_detail = self.head_detail_to_time(h_detail)
        
        # ========== æ—¶åŸŸç›´æ¥ç›¸åŠ é‡æ„ ==========
        final_pred = pred_trend + pred_mid + pred_detail
        
        # è¾“å‡º Dropout
        final_pred = self.output_dropout(final_pred)
        
        # è°ƒæ•´è¾“å‡ºå½¢çŠ¶: (B, n_vars, target_window) -> (B, target_window, n_vars)
        final_pred = final_pred.permute(0, 2, 1).contiguous()
        
        if return_components:
            components = {
                'pred_trend': pred_trend.permute(0, 2, 1).contiguous(),
                'pred_mid': pred_mid.permute(0, 2, 1).contiguous(),
                'pred_detail': pred_detail.permute(0, 2, 1).contiguous(),
            }
            return final_pred, components
        
        return final_pred


class DeepSupervisionLoss(nn.Module):
    """
    æ·±åº¦ç›‘ç£æŸå¤±æ¨¡å—
    
    ä½¿ç”¨æ ‡å‡† SWT (éå› æœï¼Œæ— æŸ) åˆ†è§£ Ground Truthï¼Œ
    ä½œä¸ºä¸‰ä¸ªé¢‘ç‡å¤´çš„è¾…åŠ©ç›‘ç£ç›®æ ‡ã€‚
    
    Total Loss = Main Loss + Î± Ã— (Loss_Trend + Loss_Mid + Loss_Detail)
    
    Args:
        wavelet: å°æ³¢ç±»å‹ (é»˜è®¤ 'db4')
        level: åˆ†è§£å±‚æ•° (é»˜è®¤ 2ï¼Œäº§ç”Ÿ 3 ä¸ªé¢‘å¸¦)
        alpha: è¾…åŠ©æŸå¤±æƒé‡ (é»˜è®¤ 0.3)
        use_causal_swt: æ˜¯å¦ä½¿ç”¨å› æœ SWT åˆ†è§£ GT (Plan Bï¼Œé»˜è®¤ False)
    """
    
    def __init__(self, wavelet='db4', level=2, alpha=0.3, use_causal_swt=False):
        super(DeepSupervisionLoss, self).__init__()
        
        self.wavelet = wavelet
        self.level = level
        self.alpha = alpha
        self.use_causal_swt = use_causal_swt
        self.num_bands = level + 1
        
        # å°è¯•å¯¼å…¥å°æ³¢æ¨¡å—
        self._init_swt()
        
        print("=" * 70)
        print("[DeepSupervisionLoss] æ·±åº¦ç›‘ç£æŸå¤±å·²å¯ç”¨")
        print("=" * 70)
        print(f"  â”œâ”€ å°æ³¢ç±»å‹: {wavelet}")
        print(f"  â”œâ”€ åˆ†è§£å±‚æ•°: {level}")
        print(f"  â”œâ”€ é¢‘å¸¦æ•°é‡: {self.num_bands}")
        print(f"  â”œâ”€ è¾…åŠ©æŸå¤±æƒé‡ Î±: {alpha}")
        print(f"  â”œâ”€ SWT ç±»å‹: {'Causal (Plan B)' if use_causal_swt else 'Standard (Plan A)'}")
        print(f"  â””â”€ Loss å…¬å¼: Main + Î± Ã— (Aux_Trend + Aux_Mid + Aux_Detail)")
        print("=" * 70)
    
    def _init_swt(self):
        """åˆå§‹åŒ– SWT æ¨¡å—"""
        if self.use_causal_swt:
            # Plan B: ä½¿ç”¨å› æœ SWT
            try:
                from layers.CausalWavelet import CausalSWT
            except ImportError:
                from .CausalWavelet import CausalSWT
            self.swt = CausalSWT(wavelet=self.wavelet, level=self.level)
            self.swt_type = 'causal'
        else:
            # Plan A: ä½¿ç”¨æ ‡å‡† SWT (å°è¯• ptwtï¼Œå¦åˆ™å›é€€åˆ°å› æœç‰ˆæœ¬)
            try:
                import ptwt
                import pywt
                self.swt_type = 'standard'
                self._ptwt = ptwt
                self._pywt = pywt
            except ImportError:
                print("[Warning] ptwt/pywt æœªå®‰è£…ï¼Œå›é€€åˆ° CausalSWT")
                try:
                    from layers.CausalWavelet import CausalSWT
                except ImportError:
                    from .CausalWavelet import CausalSWT
                self.swt = CausalSWT(wavelet=self.wavelet, level=self.level)
                self.swt_type = 'causal'
    
    def _standard_swt(self, x):
        """
        æ ‡å‡† SWT åˆ†è§£ (éå› æœï¼Œä½¿ç”¨ ptwt)
        
        Args:
            x: (B, N, T) è¾“å…¥ä¿¡å·
        
        Returns:
            coeffs: (B, N, T, num_bands) å°æ³¢ç³»æ•°
        """
        B, N, T = x.shape
        device = x.device
        dtype = x.dtype
        
        # ptwt.swt éœ€è¦ (B, T) æˆ– (B, C, T) è¾“å…¥
        # æˆ‘ä»¬é€å˜é‡å¤„ç†
        x_flat = x.reshape(B * N, T)
        
        # è½¬ä¸º float32 (ptwt å¯èƒ½ä¸æ”¯æŒ bfloat16)
        x_float = x_flat.float()
        
        # SWT åˆ†è§£
        coeffs_list = self._ptwt.swt(x_float, self._pywt.Wavelet(self.wavelet), level=self.level)
        
        # coeffs_list æ˜¯ [(cA, cD), (cA, cD), ...] æˆ– [cD1, cD2, ..., cA]
        # ptwt.swt è¿”å›æ ¼å¼: list of (cA, cD) tuples, ä» level 1 åˆ° level n
        # æˆ‘ä»¬éœ€è¦é‡ç»„ä¸º [cA_n, cD_n, cD_{n-1}, ..., cD_1]
        
        all_bands = []
        
        # æå–æœ€ç»ˆçš„è¿‘ä¼¼ç³»æ•° cA
        cA = coeffs_list[-1][0]  # æœ€åä¸€å±‚çš„ cA
        all_bands.append(cA)
        
        # æå–ç»†èŠ‚ç³»æ•° cD (ä»é«˜å±‚åˆ°ä½å±‚)
        for i in range(self.level - 1, -1, -1):
            cD = coeffs_list[i][1]
            all_bands.append(cD)
        
        # Stack: (B*N, T, num_bands)
        coeffs = torch.stack(all_bands, dim=-1)
        
        # Reshape: (B*N, T, num_bands) -> (B, N, T, num_bands)
        coeffs = coeffs.reshape(B, N, T, self.num_bands)
        
        # è½¬å›åŸå§‹ dtype
        coeffs = coeffs.to(dtype)
        
        return coeffs
    
    def _decompose_target(self, target):
        """
        åˆ†è§£ç›®æ ‡åºåˆ—
        
        Args:
            target: (B, T, N) Ground Truth
        
        Returns:
            target_bands: dict, åŒ…å« 'trend', 'mid', 'detail'
        """
        # è°ƒæ•´å½¢çŠ¶: (B, T, N) -> (B, N, T)
        target = target.permute(0, 2, 1).contiguous()
        B, N, T = target.shape
        
        if self.swt_type == 'standard':
            coeffs = self._standard_swt(target)
        else:
            coeffs = self.swt(target)
        
        # coeffs: (B, N, T, num_bands)
        # é¡ºåº: [cA_n (trend), cD_n (mid), cD_1 (detail)]
        
        # å¯¹äº level=2: [cA2, cD2, cD1]
        target_trend = coeffs[:, :, :, 0]    # cA: ä½é¢‘è¶‹åŠ¿
        target_mid = coeffs[:, :, :, 1]      # cD2: ä¸­é¢‘
        target_detail = coeffs[:, :, :, -1]  # cD1: é«˜é¢‘ç»†èŠ‚
        
        # è½¬å› (B, T, N) æ ¼å¼
        target_bands = {
            'trend': target_trend.permute(0, 2, 1).contiguous(),
            'mid': target_mid.permute(0, 2, 1).contiguous(),
            'detail': target_detail.permute(0, 2, 1).contiguous(),
        }
        
        return target_bands
    
    def forward(self, pred, target, components=None, main_loss=None):
        """
        è®¡ç®—æ·±åº¦ç›‘ç£æŸå¤±
        
        Args:
            pred: (B, T, N) æ¨¡å‹é¢„æµ‹
            target: (B, T, N) Ground Truth
            components: dict, åŒ…å« 'pred_trend', 'pred_mid', 'pred_detail'
            main_loss: é¢„è®¡ç®—çš„ä¸»æŸå¤± (å¯é€‰)
        
        Returns:
            total_loss: æ€»æŸå¤±
            loss_dict: åŒ…å«å„é¡¹æŸå¤±çš„å­—å…¸
        """
        # è®¡ç®—ä¸»æŸå¤±
        if main_loss is None:
            main_loss = F.mse_loss(pred, target)
        
        loss_dict = {'main_loss': main_loss.item()}
        
        # å¦‚æœæ²¡æœ‰æä¾›åˆ†é‡ï¼Œåªè¿”å›ä¸»æŸå¤±
        if components is None:
            return main_loss, loss_dict
        
        # åˆ†è§£ç›®æ ‡
        target_bands = self._decompose_target(target)
        
        # è®¡ç®—è¾…åŠ©æŸå¤±
        loss_trend = F.mse_loss(components['pred_trend'], target_bands['trend'])
        loss_mid = F.mse_loss(components['pred_mid'], target_bands['mid'])
        loss_detail = F.mse_loss(components['pred_detail'], target_bands['detail'])
        
        # æ€»è¾…åŠ©æŸå¤±
        aux_loss = loss_trend + loss_mid + loss_detail
        
        # æ€»æŸå¤±
        total_loss = main_loss + self.alpha * aux_loss
        
        # è®°å½•å„é¡¹æŸå¤±
        loss_dict.update({
            'loss_trend': loss_trend.item(),
            'loss_mid': loss_mid.item(),
            'loss_detail': loss_detail.item(),
            'aux_loss': aux_loss.item(),
            'total_loss': total_loss.item(),
            'alpha': self.alpha,
        })
        
        return total_loss, loss_dict


# ============================================================================
# æµ‹è¯•ä»£ç 
# ============================================================================

if __name__ == "__main__":
    import sys
    import os
    # æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
    project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
    sys.path.insert(0, project_root)
    
    print("=" * 70)
    print("TriBandDecoupledHead æ¨¡å—æµ‹è¯•")
    print("=" * 70)
    
    # è®¾å¤‡é€‰æ‹©
    device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
    print(f"\nè®¾å¤‡: {device}")
    
    # æµ‹è¯•å‚æ•°
    B = 4           # Batch size
    N = 7           # å˜é‡æ•°
    d_ff = 32       # FFN ç»´åº¦
    patch_nums = 10 # Patch æ•°é‡
    pred_len = 96   # é¢„æµ‹é•¿åº¦
    
    nf = d_ff * patch_nums  # ç‰¹å¾ç»´åº¦
    
    print(f"\næµ‹è¯•é…ç½®:")
    print(f"  - Batch: {B}, Variables: {N}")
    print(f"  - d_ff: {d_ff}, patch_nums: {patch_nums}")
    print(f"  - nf (d_ff * patch_nums): {nf}")
    print(f"  - pred_len: {pred_len}")
    
    # ========== æµ‹è¯• 1: åŸºæœ¬å‰å‘ä¼ æ’­ ==========
    print("\n" + "=" * 70)
    print("æµ‹è¯• 1: åŸºæœ¬å‰å‘ä¼ æ’­")
    print("=" * 70)
    
    head = TriBandDecoupledHead(
        n_vars=N,
        nf=nf,
        target_window=pred_len,
        head_dropout=0.1,
        mid_dropout=0.2,
        high_dropout=0.5,
        use_soft_threshold=True,
        soft_threshold_init=0.1,
        use_conv=False
    ).to(device)
    
    # æ¨¡æ‹Ÿ LLM è¾“å‡º
    x = torch.randn(B, N, d_ff, patch_nums, device=device)
    print(f"\nè¾“å…¥å½¢çŠ¶: {x.shape}")
    
    # å‰å‘ä¼ æ’­ (ä¸è¿”å›åˆ†é‡)
    output = head(x, return_components=False)
    print(f"è¾“å‡ºå½¢çŠ¶: {output.shape}")
    assert output.shape == (B, pred_len, N), f"è¾“å‡ºå½¢çŠ¶é”™è¯¯: {output.shape}"
    print("âœ… åŸºæœ¬å‰å‘ä¼ æ’­é€šè¿‡")
    
    # ========== æµ‹è¯• 2: è¿”å›é¢‘ç‡åˆ†é‡ ==========
    print("\n" + "=" * 70)
    print("æµ‹è¯• 2: è¿”å›é¢‘ç‡åˆ†é‡ (ç”¨äºæ·±åº¦ç›‘ç£)")
    print("=" * 70)
    
    output, components = head(x, return_components=True)
    print(f"\næœ€ç»ˆé¢„æµ‹å½¢çŠ¶: {output.shape}")
    print(f"è¶‹åŠ¿åˆ†é‡å½¢çŠ¶: {components['pred_trend'].shape}")
    print(f"ä¸­é¢‘åˆ†é‡å½¢çŠ¶: {components['pred_mid'].shape}")
    print(f"ç»†èŠ‚åˆ†é‡å½¢çŠ¶: {components['pred_detail'].shape}")
    
    # éªŒè¯åˆ†é‡ç›¸åŠ ç­‰äºæ€»é¢„æµ‹
    reconstructed = components['pred_trend'] + components['pred_mid'] + components['pred_detail']
    diff = (output - reconstructed).abs().max().item()
    print(f"\nåˆ†é‡ç›¸åŠ  vs æœ€ç»ˆè¾“å‡º å·®å¼‚: {diff:.10f}")
    
    # æ³¨æ„ï¼šç”±äºè¾“å‡º Dropoutï¼Œeval æ¨¡å¼ä¸‹åº”è¯¥ç›¸ç­‰
    head.eval()
    with torch.no_grad():
        output_eval, components_eval = head(x, return_components=True)
        reconstructed_eval = components_eval['pred_trend'] + components_eval['pred_mid'] + components_eval['pred_detail']
        diff_eval = (output_eval - reconstructed_eval).abs().max().item()
    print(f"(eval æ¨¡å¼) åˆ†é‡ç›¸åŠ  vs æœ€ç»ˆè¾“å‡º å·®å¼‚: {diff_eval:.10f}")
    assert diff_eval < 1e-5, "åˆ†é‡é‡æ„ä¸ä¸€è‡´!"
    print("âœ… é¢‘ç‡åˆ†é‡è¿”å›æ­£ç¡®")
    head.train()
    
    # ========== æµ‹è¯• 3: SoftThreshold åŠŸèƒ½ ==========
    print("\n" + "=" * 70)
    print("æµ‹è¯• 3: SoftThreshold åŠŸèƒ½")
    print("=" * 70)
    
    st = SoftThreshold(num_features=64, init_tau=0.1).to(device)
    
    # æµ‹è¯•è¾“å…¥
    test_input = torch.randn(B, 64, device=device)
    test_output = st(test_input)
    
    # æ£€æŸ¥å°äºé˜ˆå€¼çš„å€¼æ˜¯å¦è¢«ç½®é›¶
    tau = st.tau.abs()
    small_values_mask = test_input.abs() < tau
    zero_check = (test_output[small_values_mask] == 0).all()
    print(f"\né˜ˆå€¼ Ï„ å‡å€¼: {tau.mean().item():.4f}")
    print(f"å°äºé˜ˆå€¼çš„è¾“å…¥è¢«ç½®é›¶: {zero_check.item()}")
    print("âœ… SoftThreshold åŠŸèƒ½æ­£ç¡®")
    
    # ========== æµ‹è¯• 4: æ·±åº¦ç›‘ç£æŸå¤± ==========
    print("\n" + "=" * 70)
    print("æµ‹è¯• 4: æ·±åº¦ç›‘ç£æŸå¤± (DeepSupervisionLoss)")
    print("=" * 70)
    
    # åˆ›å»ºæ·±åº¦ç›‘ç£æŸå¤±æ¨¡å— (ä½¿ç”¨å› æœ SWTï¼Œå› ä¸ºæ ‡å‡† SWT å¯èƒ½æ²¡è£… ptwt)
    ds_loss = DeepSupervisionLoss(
        wavelet='db4',
        level=2,
        alpha=0.3,
        use_causal_swt=True  # ä½¿ç”¨å› æœç‰ˆæœ¬ä»¥ç¡®ä¿æµ‹è¯•é€šè¿‡
    ).to(device)
    
    # æ¨¡æ‹Ÿé¢„æµ‹å’Œç›®æ ‡
    pred = torch.randn(B, pred_len, N, device=device)
    target = torch.randn(B, pred_len, N, device=device)
    
    # è·å–åˆ†é‡
    head.eval()
    with torch.no_grad():
        _, components = head(x, return_components=True)
    head.train()
    
    # è®¡ç®—æŸå¤±
    total_loss, loss_dict = ds_loss(pred, target, components)
    
    print(f"\næŸå¤±è¯¦æƒ…:")
    for k, v in loss_dict.items():
        if isinstance(v, float):
            print(f"  - {k}: {v:.6f}")
        else:
            print(f"  - {k}: {v}")
    
    print(f"\næ€»æŸå¤±: {total_loss.item():.6f}")
    print("âœ… æ·±åº¦ç›‘ç£æŸå¤±è®¡ç®—æ­£ç¡®")
    
    # ========== æµ‹è¯• 5: æ¢¯åº¦ä¼ æ’­ ==========
    print("\n" + "=" * 70)
    print("æµ‹è¯• 5: æ¢¯åº¦ä¼ æ’­")
    print("=" * 70)
    
    head.train()
    x.requires_grad = True
    
    output, components = head(x, return_components=True)
    loss, _ = ds_loss(output, target, components)
    loss.backward()
    
    # æ£€æŸ¥æ¢¯åº¦
    grad_check = x.grad is not None and x.grad.abs().sum() > 0
    print(f"\nè¾“å…¥æ¢¯åº¦å­˜åœ¨: {grad_check}")
    
    # æ£€æŸ¥å„ Head æƒé‡çš„æ¢¯åº¦
    for name, param in head.named_parameters():
        if param.grad is not None:
            grad_norm = param.grad.norm().item()
            print(f"  - {name}: grad_norm = {grad_norm:.6f}")
    
    print("âœ… æ¢¯åº¦ä¼ æ’­æ­£ç¡®")
    
    # ========== æµ‹è¯• 6: å‚æ•°ç»Ÿè®¡ ==========
    print("\n" + "=" * 70)
    print("æµ‹è¯• 6: å‚æ•°ç»Ÿè®¡")
    print("=" * 70)
    
    total_params = sum(p.numel() for p in head.parameters())
    trainable_params = sum(p.numel() for p in head.parameters() if p.requires_grad)
    
    print(f"\næ€»å‚æ•°é‡: {total_params:,}")
    print(f"å¯è®­ç»ƒå‚æ•°é‡: {trainable_params:,}")
    
    # åˆ†å¤´ç»Ÿè®¡
    trend_params = sum(p.numel() for n, p in head.named_parameters() if 'trend' in n)
    mid_params = sum(p.numel() for n, p in head.named_parameters() if 'mid' in n)
    detail_params = sum(p.numel() for n, p in head.named_parameters() if 'detail' in n)
    
    print(f"\nHead Trend å‚æ•°: {trend_params:,}")
    print(f"Head Mid å‚æ•°: {mid_params:,}")
    print(f"Head Detail å‚æ•°: {detail_params:,}")
    print("âœ… å‚æ•°ç»Ÿè®¡å®Œæˆ")
    
    # ========== æµ‹è¯• 7: Conv1d æ¨¡å¼ ==========
    print("\n" + "=" * 70)
    print("æµ‹è¯• 7: Conv1d æ¨¡å¼ (ä½ç½®æ„ŸçŸ¥)")
    print("=" * 70)
    
    head_conv = TriBandDecoupledHead(
        n_vars=N,
        nf=nf,
        target_window=pred_len,
        use_soft_threshold=True,
        use_conv=True  # ä½¿ç”¨ Conv1d
    ).to(device)
    
    x_test = torch.randn(B, N, d_ff, patch_nums, device=device)
    output_conv = head_conv(x_test)
    print(f"\nConv1d æ¨¡å¼è¾“å‡ºå½¢çŠ¶: {output_conv.shape}")
    assert output_conv.shape == (B, pred_len, N)
    print("âœ… Conv1d æ¨¡å¼æ­£ç¡®")
    
    # ========== æµ‹è¯•å®Œæˆ ==========
    print("\n" + "=" * 70)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡!")
    print("=" * 70)

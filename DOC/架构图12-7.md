让我先阅读这些文件来理解模型架构。

继续读取剩余的关键文件和TimeLLM.py的后半部分。

根据代码分析，SWT-Time 模型架构如下：

```mermaid
flowchart TB
    subgraph Input["输入处理"]
        X["x_enc<br/>(B, T, N)"]
        Norm["Normalize<br/>RevIN标准化"]
    end

    subgraph Stats["统计特征提取"]
        MinMax["min/max/median"]
        Trends["趋势方向"]
        Lags["Top-K自相关滞后<br/>(FFT计算)"]
        FreqAnalyzer["FrequencyAnalyzer<br/>(可选: 频域Prompt)"]
    end

    subgraph Prompt["Prompt构建"]
        PromptText["Text Prompt<br/>数据描述+任务描述+统计特征"]
        Tokenizer["LLM Tokenizer"]
        PromptEmbed["Prompt Embeddings"]
    end

    subgraph PatchEmbed["Patch Embedding (二选一)"]
        direction TB
        subgraph Original["原始方案"]
            PE["PatchEmbedding<br/>Patching → Conv1d"]
        end
        subgraph Wavelet["小波增强方案"]
            SWT["SWTDecomposition<br/>平稳小波变换<br/>(B,N,T)→(B,N,T,4)"]
            BandAttn["频段注意力<br/>(静态/动态)"]
            WPE["WaveletPatchEmbedding<br/>Patching → Conv1d"]
        end
    end

    subgraph Reprogram["时序→LLM空间映射"]
        WordEmbed["LLM词嵌入"]
        MappingLayer["Mapping Layer<br/>vocab_size→num_tokens"]
        SourceEmbed["Source Embeddings"]
        ReprogLayer["ReprogrammingLayer<br/>Cross-Attention"]
    end

    subgraph LLM["冻结LLM骨干"]
        Concat["Concat<br/>[Prompt; TimeSeriesEmbed]"]
        LLMModel["GPT2 / LLAMA / BERT<br/>(冻结参数)"]
        HiddenState["LLM Hidden States"]
    end

    subgraph OutputAdapt["输出适配"]
        Adapter["Output Adapter<br/>Linear(d_llm → dec_out_dim)"]
    end

    subgraph OutputHead["输出头 (二选一)"]
        direction TB
        subgraph FH["FlattenHead"]
            Flatten["Flatten → Linear"]
        end
        subgraph WH["WaveletHead"]
            BandProj["频段独立投影<br/>(4个Linear)"]
            BandAttn2["频段注意力加权"]
            ISWT["ISWTReconstruction<br/>逆小波变换重构"]
        end
    end

    subgraph Output["输出"]
        Denorm["Normalize<br/>反标准化"]
        Pred["预测结果<br/>(B, pred_len, N)"]
    end

    %% 数据流
    X --> Norm
    Norm --> Stats
    Norm --> PatchEmbed
    
    Stats --> MinMax & Trends & Lags
    Lags --> FreqAnalyzer
    MinMax & Trends & Lags & FreqAnalyzer --> PromptText
    PromptText --> Tokenizer --> PromptEmbed
    
    %% 原始Patch路径
    PE -.-> ReprogLayer
    
    %% 小波Patch路径
    SWT --> BandAttn --> WPE --> ReprogLayer
    
    WordEmbed --> MappingLayer --> SourceEmbed --> ReprogLayer
    
    PromptEmbed --> Concat
    ReprogLayer --> Concat
    Concat --> LLMModel --> HiddenState
    HiddenState --> Adapter
    
    %% 输出头
    Adapter --> Flatten --> Denorm
    Adapter --> BandProj --> BandAttn2 --> ISWT --> Denorm
    
    Denorm --> Pred

    %% 样式
    classDef frozen fill:#e1e1e1,stroke:#666
    classDef wavelet fill:#d4edda,stroke:#28a745
    classDef attention fill:#fff3cd,stroke:#ffc107
    
    class LLMModel frozen
    class SWT,ISWT,WPE wavelet
    class BandAttn,BandAttn2,ReprogLayer attention
```

## 核心组件说明

| 模块 | 功能 | 位置 |
|------|------|------|
| **Normalize** | RevIN可逆标准化 | [StandardNorm.py](cci:7://file:///home/dmx_MT/LZF/project/SWT-Time/layers/StandardNorm.py:0:0-0:0) |
| **WaveletPatchEmbedding** | SWT分解 + 频段注意力 + Patching | [WaveletEmbed.py](cci:7://file:///home/dmx_MT/LZF/project/SWT-Time/layers/WaveletEmbed.py:0:0-0:0) |
| **SWTDecomposition** | 平稳小波变换(GPU加速) | [WaveletEmbed.py](cci:7://file:///home/dmx_MT/LZF/project/SWT-Time/layers/WaveletEmbed.py:0:0-0:0) |
| **DynamicBandAttention** | 样本级动态频段权重 | [WaveletEmbed.py](cci:7://file:///home/dmx_MT/LZF/project/SWT-Time/layers/WaveletEmbed.py:0:0-0:0) |
| **ReprogrammingLayer** | Cross-Attention重编程 | [TimeLLM.py](cci:7://file:///home/dmx_MT/LZF/project/SWT-Time/models/TimeLLM.py:0:0-0:0) |
| **WaveletHead** | 小波系数预测 + ISWT重构 | [TimeLLM.py](cci:7://file:///home/dmx_MT/LZF/project/SWT-Time/models/TimeLLM.py:0:0-0:0) |
| **ISWTReconstruction** | 逆小波变换重构 | [WaveletEmbed.py](cci:7://file:///home/dmx_MT/LZF/project/SWT-Time/layers/WaveletEmbed.py:0:0-0:0) |
| **FrequencyAnalyzer** | 频域特征分析(Prompt增强) | [TimeLLM.py](cci:7://file:///home/dmx_MT/LZF/project/SWT-Time/models/TimeLLM.py:0:0-0:0) |

## 架构亮点

- **对称小波域设计**：编码端SWT ↔ 解码端ISWT
- **频段注意力机制**：可学习的频段重要性权重
- **冻结LLM骨干**：只训练适配层，高效微调
- **边界优化**：历史系数拼接消除ISWT边界伪影


```mermaid
flowchart TB
    subgraph Input["输入"]
        X["x_enc<br/><b>(B, N, T)</b><br/>B=batch, N=变量数, T=序列长度"]
    end

    subgraph SWT_Module["SWTDecomposition 平稳小波变换"]
        direction TB
        Reshape1["Reshape<br/>(B, N, T) → (B*N, T)"]
        
        subgraph PTWT["ptwt.swt (GPU加速)"]
            direction LR
            SWT_Op["SWT分解<br/>level=3, wavelet='db4'"]
        end
        
        Extract["提取系数<br/>[cD1, cD2, cD3, cA3]"]
        Reorder["重排顺序<br/>[cA3, cD3, cD2, cD1]"]
        Stack["Stack<br/>(B*N, T) × 4 → (B*N, T, 4)"]
        Reshape2["Reshape<br/>(B*N, T, 4) → <b>(B, N, T, 4)</b>"]
    end

    subgraph Coeffs["小波系数输出"]
        direction TB
        cA3["coeffs[...,0]: <b>cA3</b><br/>近似系数(低频趋势)"]
        cD3["coeffs[...,1]: <b>cD3</b><br/>细节系数(最高频)"]
        cD2["coeffs[...,2]: <b>cD2</b><br/>细节系数(中频)"]
        cD1["coeffs[...,3]: <b>cD1</b><br/>细节系数(低频细节)"]
    end

    subgraph BandAttention["频段注意力机制"]
        direction TB
        
        subgraph Static["静态模式 (Global)"]
            StaticLogits["band_attention_logits<br/>可学习参数 (4,)"]
            StaticSoftmax["Softmax"]
            StaticW["全局权重<br/>[w_cA, w_cD3, w_cD2, w_cD1]"]
        end
        
        subgraph Dynamic["动态模式 (Instance-wise)"]
            Energy["能量池化<br/>mean(coeffs², dim=T)<br/>(B,N,T,4)→(B,N,4)"]
            MLP["MLP Router<br/>Linear(4→2)→ReLU→Linear(2→4)"]
            DynSoftmax["Softmax"]
            DynW["样本级权重<br/>(B, N, 4)"]
        end
    end

    subgraph WeightedCoeffs["加权小波系数"]
        Apply["coeffs × weights<br/><b>(B, N, T, 4)</b>"]
    end

    subgraph Patching["Patching处理"]
        direction TB
        Permute1["Permute<br/>(B,N,T,4) → (B,N,4,T)"]
        Reshape3["Reshape<br/>(B,N,4,T) → (B*N*4, T)"]
        Pad["ReplicationPad1d<br/>(B*N*4, T) → (B*N*4, T+stride)"]
        Unfold["Unfold<br/>(B*N*4, T+stride) → (B*N*4, num_patches, patch_len)"]
        Reshape4["Reshape<br/>(B*N*4, P, L) → (B*N, 4, P, L)"]
    end

    subgraph Projection["特征投影"]
        direction TB
        Conv1d["Conv1d<br/>in=patch_len, out=d_model"]
        Dropout["Dropout"]
    end

    subgraph Output["最终输出"]
        direction TB
        Concat["频段拼接<br/>(B*N, P, 4*d_model)"]
        OutShape["<b>(B*N, num_patches, 4×d_model)</b><br/>例: (56, 64, 128)"]
    end

    %% 数据流
    X --> Reshape1
    Reshape1 --> SWT_Op
    SWT_Op --> Extract --> Reorder --> Stack --> Reshape2
    
    Reshape2 --> cA3 & cD3 & cD2 & cD1
    
    %% 频段注意力分支
    Reshape2 --> StaticLogits
    StaticLogits --> StaticSoftmax --> StaticW
    
    Reshape2 --> Energy --> MLP --> DynSoftmax --> DynW
    
    StaticW -.->|静态| Apply
    DynW -.->|动态| Apply
    cA3 & cD3 & cD2 & cD1 --> Apply
    
    %% Patching流程
    Apply --> Permute1 --> Reshape3 --> Pad --> Unfold --> Reshape4
    Reshape4 --> Conv1d --> Dropout --> Concat --> OutShape


```

## 维度变换详细流程

| 步骤 | 操作 | 维度变化 | 说明 |
|------|------|----------|------|
| 1 | 输入 | `(B, N, T)` | B=8, N=7, T=512 |
| 2 | SWT分解 | `(B, N, T) → (B, N, T, 4)` | 4个频段：cA3, cD3, cD2, cD1 |
| 3 | 频段加权 | `(B, N, T, 4) × (4,)` | 静态或动态权重 |
| 4 | Permute | `(B, N, T, 4) → (B, N, 4, T)` | 调整频段维度位置 |
| 5 | Reshape | `(B*N*4, T)` | 8×7×4=224 |
| 6 | Padding | `(B*N*4, T+stride)` | 复制填充 |
| 7 | Unfold | `(B*N*4, P, L)` | P=num_patches, L=patch_len |
| 8 | Conv1d | `(B*N*4, P, d_model)` | 投影到d_model=32 |
| 9 | 频段拼接 | `(B*N, P, 4×d_model)` | 56, 64, 128 |

## 频段物理含义

| 频段 | 频率范围 | 物理意义 | 默认权重 |
|------|----------|----------|----------|
| **cA3** | 最低频 | 全局趋势、长周期模式 | 1.5 (最重要) |
| **cD3** | 最高频 | 高频噪声、快速波动 | 0.3 (抑制) |
| **cD2** | 中频 | 中期周期、季节性 | 1.0 |
| **cD1** | 中低频 | 短期波动细节 | 0.8 |



```mermaid
flowchart TB
    subgraph LLMOutput["LLM输出"]
        HiddenState["LLM Hidden States<br/><b>(B*N, seq_len, d_llm)</b><br/>d_llm=768(GPT2)/4096(LLAMA)"]
    end

    subgraph OutputAdapter["Output Adapter 输出适配器"]
        direction TB
        AdapterLinear["Linear(d_llm → dec_out_dim)<br/>768 → 128 (WaveletHead)<br/>768 → d_ff (FlattenHead)"]
        AdapterOut["<b>(B*N, seq_len, dec_out_dim)</b>"]
    end

    subgraph Reshape1["维度重组"]
        R1["Reshape<br/>(B*N, seq, dim) → (B, N, seq, dim)"]
        R2["Permute<br/>(B, N, seq, dim) → (B, N, dim, seq)"]
        R3["取最后patch_nums列<br/>(B, N, dim, patch_nums)"]
    end

    subgraph HeadChoice["输出头选择"]
        direction LR
        FH["FlattenHead<br/>直接时域映射"]
        WH["WaveletHead<br/>小波域对称解码"]
    end

    subgraph FlattenHead["FlattenHead 详细流程"]
        direction TB
        FH_Flatten["Flatten<br/>(B, N, d_ff, P) → (B, N, d_ff*P)"]
        FH_Linear["Linear(d_ff*P → pred_len)"]
        FH_Dropout["Dropout"]
        FH_Out["<b>(B, N, pred_len)</b>"]
    end

    subgraph WaveletHead["WaveletHead 详细流程"]
        direction TB
        
        subgraph Split["频段分离"]
            WH_Input["输入: (B, N, 4*d_model, P)<br/>例: (8, 7, 128, 64)"]
            WH_Split["Split(dim=2)<br/>按d_model=32分割"]
            Band0["Band0: cA3<br/>(B, N, 32, P)"]
            Band1["Band1: cD3<br/>(B, N, 32, P)"]
            Band2["Band2: cD2<br/>(B, N, 32, P)"]
            Band3["Band3: cD1<br/>(B, N, 32, P)"]
        end

        subgraph BandProj["频段独立投影"]
            Proj0["Linear(32*P → pred_len)<br/>cA3_pred"]
            Proj1["Linear(32*P → pred_len)<br/>cD3_pred"]
            Proj2["Linear(32*P → pred_len)<br/>cD2_pred"]
            Proj3["Linear(32*P → pred_len)<br/>cD1_pred"]
        end

        subgraph StackCoeffs["系数堆叠"]
            Stack["Stack(dim=-1)<br/>4×(B,N,pred_len) → (B,N,pred_len,4)"]
        end

        subgraph BandAttnDec["解码端频段注意力"]
            direction TB
            
            subgraph StaticDec["静态模式"]
                StaticLogits2["band_attention_logits<br/>可学习 (4,)"]
                StaticSoftmax2["Softmax → weights"]
            end
            
            subgraph DynamicDec["动态模式"]
                Energy2["能量池化<br/>(B,N,pred_len,4)→(B,N,4)"]
                MLP2["MLP Router"]
                DynWeights2["样本级权重<br/>(B, N, 4)"]
            end
            
            ApplyWeights["coeffs × weights<br/>(B, N, pred_len, 4)"]
        end

        subgraph Boundary["边界优化 (可选)"]
            HistCoeffs["历史小波系数<br/>history_coeffs<br/>(B, N, T, 4)"]
            HistSuffix["取尾部filter_len点<br/>(B, N, filter_len, 4)"]
            Concat["Concat<br/>[history | pred_coeffs]<br/>(B, N, filter_len+pred_len, 4)"]
        end

        subgraph ISWT["ISWTReconstruction 逆小波变换"]
            direction TB
            ISWT_Reshape["Reshape<br/>(B,N,L,4) → (B*N,L,4)"]
            ISWT_Reorder["重排系数顺序<br/>[cA,cD3,cD2,cD1]→[cD1,cD2,cD3,cA]"]
            ISWT_Op["ptwt.iswt<br/>GPU加速逆变换"]
            ISWT_Reshape2["Reshape<br/>(B*N, L) → (B, N, L)"]
            ISWT_Crop["裁剪边界部分<br/>(B, N, pred_len)"]
        end

        WH_Out["<b>(B, N, pred_len)</b>"]
    end

    subgraph PostProcess["后处理"]
        Permute2["Permute<br/>(B, N, pred_len) → (B, pred_len, N)"]
        Denorm["Normalize.denorm<br/>反标准化"]
    end

    subgraph FinalOutput["最终输出"]
        Pred["预测结果<br/><b>(B, pred_len, N)</b>"]
        OptCoeffs["可选: 预测小波系数<br/>(B, N, pred_len, 4)<br/>用于混合损失函数"]
    end

    %% 主数据流
    HiddenState --> AdapterLinear --> AdapterOut
    AdapterOut --> R1 --> R2 --> R3
    R3 --> HeadChoice
    
    %% FlattenHead分支
    HeadChoice -->|原始| FH
    FH --> FH_Flatten --> FH_Linear --> FH_Dropout --> FH_Out
    
    %% WaveletHead分支
    HeadChoice -->|小波| WH
    WH --> WH_Input --> WH_Split
    WH_Split --> Band0 & Band1 & Band2 & Band3
    
    Band0 --> Proj0
    Band1 --> Proj1
    Band2 --> Proj2
    Band3 --> Proj3
    
    Proj0 & Proj1 & Proj2 & Proj3 --> Stack
    
    Stack --> StaticLogits2 --> StaticSoftmax2 --> ApplyWeights
    Stack --> Energy2 --> MLP2 --> DynWeights2 --> ApplyWeights
    
    %% 边界优化
    HistCoeffs --> HistSuffix --> Concat
    ApplyWeights --> Concat
    
    %% ISWT
    Concat --> ISWT_Reshape --> ISWT_Reorder --> ISWT_Op --> ISWT_Reshape2 --> ISWT_Crop --> WH_Out
    
    %% 后处理
    FH_Out --> Permute2
    WH_Out --> Permute2
    Permute2 --> Denorm --> Pred
    
    ApplyWeights -.->|return_coeffs=True| OptCoeffs

    %% 样式

    
    class HiddenState llm
    class AdapterLinear,AdapterOut adapter
    class ISWT_Op,ISWT_Reorder,Stack,WH_Split wavelet
    class StaticLogits2,StaticSoftmax2,Energy2,MLP2,DynWeights2,ApplyWeights attn
    class Pred,OptCoeffs output
    class HistCoeffs,HistSuffix,Concat boundary
```

## 维度变换详细流程

| 步骤 | 操作 | 维度 | 说明 |
|------|------|------|------|
| **LLM输出** | Hidden States | `(B*N, seq, 768)` | GPT2的d_llm=768 |
| **Output Adapter** | Linear | `(B*N, seq, 128)` | 投影到4×d_model |
| **Reshape** | 维度重组 | `(B, N, 128, P)` | P=patch_nums |
| **Split** | 频段分离 | `4×(B, N, 32, P)` | 分回4个频段 |
| **投影** | 4个独立Linear | `4×(B, N, pred_len)` | 每频段独立预测 |
| **Stack** | 堆叠 | `(B, N, pred_len, 4)` | 组成小波系数 |
| **加权** | 频段注意力 | `(B, N, pred_len, 4)` | 加权调整 |
| **边界拼接** | Concat | `(B, N, L+pred_len, 4)` | L=filter_len |
| **ISWT** | 逆小波变换 | `(B, N, L+pred_len)` | 重构时域 |
| **裁剪** | 去除边界 | `(B, N, pred_len)` | 最终预测 |
| **Permute** | 维度调整 | `(B, pred_len, N)` | 标准输出格式 |

## 编码-解码对称性

```mermaid
flowchart LR
    subgraph Encoder["编码端 WaveletPatchEmbedding"]
        E1["时域输入<br/>(B,N,T)"]
        E2["SWT分解<br/>→4频段"]
        E3["频段加权"]
        E4["Patching"]
        E5["Conv投影<br/>→d_model"]
        E6["频段拼接<br/>→4*d_model"]
    end
    
    subgraph LLM_Block["LLM处理"]
        L1["Reprogramming"]
        L2["冻结LLM"]
        L3["Output Adapter"]
    end
    
    subgraph Decoder["解码端 WaveletHead"]
        D1["频段分离<br/>←4*d_model"]
        D2["Linear投影<br/>←d_model"]
        D3["独立预测<br/>4个系数"]
        D4["频段加权"]
        D5["ISWT重构<br/>←4频段"]
        D6["时域输出<br/>(B,N,pred_len)"]
    end
    
    E1 --> E2 --> E3 --> E4 --> E5 --> E6
    E6 --> L1 --> L2 --> L3
    L3 --> D1 --> D2 --> D3 --> D4 --> D5 --> D6
    
    E2 <-.->|对称| D5
    E3 <-.->|对称| D4
    E5 <-.->|对称| D2
    E6 <-.->|对称| D1
    
    classDef enc fill:#d4edda,stroke:#28a745
    classDef dec fill:#e3f2fd,stroke:#1976d2
    classDef llm fill:#e1e1e1,stroke:#666
    
    class E1,E2,E3,E4,E5,E6 enc
    class D1,D2,D3,D4,D5,D6 dec
    class L1,L2,L3 llm
```

## 边界优化原理

| 问题 | 原因 | 解决方案 |
|------|------|----------|
| **ISWT边界伪影** | 滤波器卷积在t=0处缺少历史上下文 | 拼接历史小波系数 |
| **历史系数来源** | 编码端SWT已分解过历史序列 | 复用`patch_embedding.swt(x_enc)` |
| **拼接长度** | 由小波滤波器长度决定 | `filter_len = wavelet.dec_len` (db4=8) |
| **裁剪输出** | 去除拼接的历史部分 | `pred = recon[:, :, filter_len:]` |
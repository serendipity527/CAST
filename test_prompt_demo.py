#!/usr/bin/env python3
"""
æ¼”ç¤ºå°æ³¢ç‰¹å¾é›†æˆåˆ°TimeLLM Promptçš„å®é™…æ•ˆæœ
å±•ç¤ºå®Œæ•´çš„promptç”Ÿæˆç»“æœ
"""

import torch
import numpy as np
from models.TimeLLM import Model
import argparse

def create_demo_config():
    """åˆ›å»ºæ¼”ç¤ºé…ç½®"""
    class DemoConfig:
        def __init__(self):
            # åŸºæœ¬é…ç½®
            self.task_name = 'long_term_forecast'
            self.pred_len = 24
            self.seq_len = 96
            self.d_ff = 32
            self.llm_dim = 768
            self.patch_len = 16
            self.stride = 8
            self.enc_in = 7  # ETTæ•°æ®é›†çš„å˜é‡æ•°
            self.dropout = 0.1
            self.d_model = 16
            self.n_heads = 8
            self.llm_layers = 2
            
            # LLMé…ç½®
            self.llm_model = 'GPT2'
            self.prompt_domain = 0
            
            # å°æ³¢é…ç½®
            self.wavelet_mode = 'none'
            self.use_haar_wavelet = 0
            
            # è¾“å‡ºå¤´é…ç½®
            self.use_dual_scale_head = 0
            self.use_freq_decoupled_head = 0
    
    return DemoConfig()

def create_realistic_signals():
    """åˆ›å»ºæ›´çœŸå®çš„æ—¶é—´åºåˆ—æ•°æ®"""
    T = 96
    B = 3  # 3ä¸ªæ ·æœ¬
    N = 7  # 7ä¸ªå˜é‡ï¼ˆæ¨¡æ‹ŸETTæ•°æ®é›†ï¼‰
    
    # åˆ›å»ºæ¨¡æ‹Ÿçš„ETTæ•°æ®
    t = torch.linspace(0, 4*np.pi, T)
    
    signals = torch.zeros(B, T, N)
    
    # æ ·æœ¬1: å¹³ç¨³çš„ç”µåŠ›è´Ÿè·æ•°æ®ï¼ˆä½é¢‘ä¸»å¯¼ï¼‰
    for i in range(N):
        base_trend = 50 + 10 * torch.sin(0.5 * t + i * 0.1)  # åŸºç¡€è¶‹åŠ¿
        daily_cycle = 5 * torch.sin(2 * t + i * 0.2)  # æ—¥å‘¨æœŸ
        noise = 0.5 * torch.randn(T)  # å°å™ªå£°
        signals[0, :, i] = base_trend + daily_cycle + noise
    
    # æ ·æœ¬2: æ³¢åŠ¨çš„æ¸©åº¦æ•°æ®ï¼ˆä¸­ç­‰æ³¢åŠ¨ï¼‰
    for i in range(N):
        base_temp = 20 + 15 * torch.sin(0.3 * t + i * 0.15)
        weather_var = 3 * torch.sin(4 * t + i * 0.3) * torch.exp(-0.1 * t)
        noise = 1.0 * torch.randn(T)
        signals[1, :, i] = base_temp + weather_var + noise
    
    # æ ·æœ¬3: é«˜é¢‘å™ªå£°æ•°æ®ï¼ˆè®¾å¤‡æ•…éšœåœºæ™¯ï¼‰
    for i in range(N):
        base_signal = 30 + 2 * t / T  # è½»å¾®è¶‹åŠ¿
        high_freq_noise = 8 * torch.randn(T)  # å¼ºå™ªå£°
        spikes = 15 * (torch.rand(T) > 0.95).float()  # éšæœºå°–å³°
        signals[2, :, i] = base_signal + high_freq_noise + spikes
    
    return signals

def demo_full_prompt_generation():
    """æ¼”ç¤ºå®Œæ•´çš„promptç”Ÿæˆè¿‡ç¨‹"""
    print("ğŸ¯ TimeLLMå°æ³¢Promptå®Œæ•´æ¼”ç¤º")
    print("=" * 80)
    
    try:
        # åˆ›å»ºæ¨¡å‹
        config = create_demo_config()
        model = Model(config)
        
        # åˆ›å»ºçœŸå®çš„æµ‹è¯•æ•°æ®
        x_enc = create_realistic_signals()  # (B=3, T=96, N=7)
        print(f"è¾“å…¥æ•°æ®å½¢çŠ¶: {x_enc.shape}")
        
        # æ¨¡æ‹Ÿæ—¶é—´æ ‡è®°ï¼ˆå¯ä»¥æ˜¯ç©ºçš„ï¼‰
        x_mark_enc = torch.zeros(x_enc.shape[0], x_enc.shape[1], 4)  # æ—¶é—´ç‰¹å¾
        x_dec = torch.zeros(x_enc.shape[0], config.pred_len, x_enc.shape[2])
        x_mark_dec = torch.zeros(x_enc.shape[0], config.pred_len, 4)
        
        # æ‰‹åŠ¨æ‰§è¡Œforecastå‡½æ•°çš„å‰åŠéƒ¨åˆ†æ¥è·å–prompt
        print("\n" + "=" * 80)
        print("ç”Ÿæˆçš„Promptç¤ºä¾‹")
        print("=" * 80)
        
        # å½’ä¸€åŒ–
        x_enc_norm = model.normalize_layers(x_enc, 'norm')
        
        B, T, N = x_enc_norm.size()
        x_enc_reshaped = x_enc_norm.permute(0, 2, 1).contiguous().reshape(B * N, T, 1)
        
        # è®¡ç®—ç»Ÿè®¡é‡
        min_values = torch.min(x_enc_reshaped, dim=1)[0]
        max_values = torch.max(x_enc_reshaped, dim=1)[0]
        medians = torch.median(x_enc_reshaped, dim=1).values
        lags = model.calcute_lags(x_enc_reshaped)
        trends = x_enc_reshaped.diff(dim=1).sum(dim=1)
        
        # ç”Ÿæˆpromptï¼ˆåªæ˜¾ç¤ºå‰å‡ ä¸ªæ ·æœ¬ï¼‰
        sample_indices = [0, 7, 14]  # æ¯ä¸ªbatchçš„ç¬¬ä¸€ä¸ªå˜é‡
        scenario_names = ["å¹³ç¨³ç”µåŠ›è´Ÿè·", "æ³¢åŠ¨æ¸©åº¦æ•°æ®", "é«˜é¢‘å™ªå£°æ•°æ®"]
        
        for idx, (sample_idx, scenario) in enumerate(zip(sample_indices, scenario_names)):
            print(f"\nğŸ“Š åœºæ™¯ {idx+1}: {scenario}")
            print("-" * 60)
            
            # æ ¼å¼åŒ–ç»Ÿè®¡å€¼
            min_val = min_values[sample_idx].tolist()[0]
            max_val = max_values[sample_idx].tolist()[0]
            median_val = medians[sample_idx].tolist()[0]
            
            min_values_str = f"{min_val:.3f}"
            max_values_str = f"{max_val:.3f}"
            median_values_str = f"{median_val:.3f}"
            lags_values_str = str(lags[sample_idx].tolist())
            
            # å°æ³¢ç‰¹å¾åˆ†æ
            current_x = x_enc_reshaped[sample_idx, :, 0]
            hfer, volatility, smoothness_level = model.analyze_wavelet_features(current_x)
            wavelet_desc = model.get_wavelet_description(hfer, volatility, smoothness_level)
            
            # ç”Ÿæˆå®Œæ•´prompt
            prompt = (
                f"<|start_prompt|>Dataset description: {model.description}"
                f"Task description: forecast the next {str(model.pred_len)} steps given the previous {str(model.seq_len)} steps information; "
                "Input statistics: "
                f"min value {min_values_str}, "
                f"max value {max_values_str}, "
                f"median value {median_values_str}, "
                f"the trend of input is {'upward' if trends[sample_idx] > 0 else 'downward'}, "
                f"top 5 lags are : {lags_values_str}; "
                f"Frequency characteristics: {wavelet_desc}."
                f"<|<end_prompt>|>"
            )
            
            print("ğŸ”¤ ç”Ÿæˆçš„Prompt:")
            print(prompt)
            
            print(f"\nğŸ“ˆ å°æ³¢ç‰¹å¾è¯¦æƒ…:")
            print(f"  - é«˜é¢‘èƒ½é‡å æ¯”: {hfer:.3f} ({hfer*100:.1f}%)")
            print(f"  - æ³¢åŠ¨æ€§æŒ‡æ ‡: {volatility:.3f}")
            print(f"  - å¹³æ»‘åº¦ç­‰çº§: {smoothness_level}/4")
            
        print("\n" + "=" * 80)
        print("âœ… å®Œæ•´æ¼”ç¤ºæˆåŠŸï¼")
        
        # å¯¹æ¯”åˆ†æ
        print("\nğŸ“Š ä¸åŒåœºæ™¯çš„å°æ³¢ç‰¹å¾å¯¹æ¯”:")
        print("-" * 60)
        print(f"{'åœºæ™¯':<12} {'HFER':<8} {'æ³¢åŠ¨æ€§':<8} {'ç­‰çº§':<4} {'LLMç†è§£'}")
        print("-" * 60)
        
        for idx, (sample_idx, scenario) in enumerate(zip(sample_indices, scenario_names)):
            current_x = x_enc_reshaped[sample_idx, :, 0]
            hfer, volatility, smoothness_level = model.analyze_wavelet_features(current_x)
            
            if smoothness_level <= 1:
                llm_hint = "å…³æ³¨è¶‹åŠ¿é¢„æµ‹"
            elif smoothness_level <= 2:
                llm_hint = "å¹³è¡¡è¶‹åŠ¿ä¸æ³¢åŠ¨"
            else:
                llm_hint = "è°¨æ…å¤„ç†å™ªå£°"
            
            print(f"{scenario:<12} {hfer:<8.3f} {volatility:<8.3f} {smoothness_level:<4} {llm_hint}")
        
    except Exception as e:
        print(f"âŒ æ¼”ç¤ºå¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

def compare_before_after():
    """å¯¹æ¯”æ·»åŠ å°æ³¢ç‰¹å¾å‰åçš„prompt"""
    print("\n" + "=" * 80)
    print("ğŸ”„ Promptå¯¹æ¯”ï¼šæ·»åŠ å°æ³¢ç‰¹å¾å‰ vs å")
    print("=" * 80)
    
    # æ¨¡æ‹Ÿæ•°æ®
    min_val, max_val, median_val = 1.234, 5.678, 3.456
    trend = "upward"
    lags = [1, 24, 48, 72, 96]
    
    # æ¨¡æ‹Ÿå°æ³¢ç‰¹å¾
    hfer, volatility, smoothness_level = 0.156, 0.423, 2
    
    print("ğŸ“œ åŸå§‹Prompt (æ— å°æ³¢ç‰¹å¾):")
    print("-" * 40)
    original_prompt = (
        f"<|start_prompt|>Dataset description: The Electricity Transformer Temperature (ETT) is a crucial indicator in the electric power long-term deployment."
        f"Task description: forecast the next 24 steps given the previous 96 steps information; "
        "Input statistics: "
        f"min value {min_val:.3f}, "
        f"max value {max_val:.3f}, "
        f"median value {median_val:.3f}, "
        f"the trend of input is {trend}, "
        f"top 5 lags are : {lags}"
        f"<|<end_prompt>|>"
    )
    print(original_prompt)
    
    print(f"\nğŸ“Š å¢å¼ºPrompt (å«å°æ³¢ç‰¹å¾):")
    print("-" * 40)
    wavelet_desc = f"The signal is moderately smooth with some variations with moderate volatility (HF energy: {hfer:.1%})"
    enhanced_prompt = (
        f"<|start_prompt|>Dataset description: The Electricity Transformer Temperature (ETT) is a crucial indicator in the electric power long-term deployment."
        f"Task description: forecast the next 24 steps given the previous 96 steps information; "
        "Input statistics: "
        f"min value {min_val:.3f}, "
        f"max value {max_val:.3f}, "
        f"median value {median_val:.3f}, "
        f"the trend of input is {trend}, "
        f"top 5 lags are : {lags}; "
        f"Frequency characteristics: {wavelet_desc}."
        f"<|<end_prompt>|>"
    )
    print(enhanced_prompt)
    
    print(f"\nğŸ¯ å…³é”®æ”¹è¿›:")
    print("1. âœ… æ·»åŠ äº†é¢‘åŸŸç‰¹å¾æè¿°")
    print("2. âœ… é‡åŒ–äº†ä¿¡å·çš„å¹³æ»‘åº¦å’Œæ³¢åŠ¨æ€§")
    print("3. âœ… ä¸ºLLMæä¾›äº†æ›´ä¸°å¯Œçš„ä¸Šä¸‹æ–‡ä¿¡æ¯")
    print("4. âœ… å¸®åŠ©LLMç†è§£åº”è¯¥é‡‡ç”¨ä¿å®ˆè¿˜æ˜¯æ¿€è¿›çš„é¢„æµ‹ç­–ç•¥")

if __name__ == "__main__":
    # å®Œæ•´æ¼”ç¤º
    demo_full_prompt_generation()
    
    # å¯¹æ¯”åˆ†æ
    compare_before_after()
    
    print("\n" + "ğŸ‰" * 20)
    print("å°æ³¢ç‰¹å¾é›†æˆåˆ°TimeLLM Promptçš„å®ç°å·²å®Œæˆï¼")
    print("ğŸ‰" * 20)
